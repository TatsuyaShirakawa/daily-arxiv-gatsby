---
title: Hot Papers 2020-09-29
date: 2020-09-30T09:24:37.Z
template: "post"
draft: false
slug: "hot-papers-2020-09-29"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2020-09-29"
socialImage: "/media/flying-marine.jpg"

---

# 1. Parametric UMAP: learning embeddings with deep neural networks for  representation and semi-supervised learning

Tim Sainburg, Leland McInnes, Timothy Q Gentner

- retweets: 1484, favorites: 137 (09/30/2020 09:24:37)

- links: [abs](https://arxiv.org/abs/2009.12981) | [pdf](https://arxiv.org/pdf/2009.12981)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.CG](https://arxiv.org/list/cs.CG/recent) | [q-bio.QM](https://arxiv.org/list/q-bio.QM/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

We propose Parametric UMAP, a parametric variation of the UMAP (Uniform Manifold Approximation and Projection) algorithm. UMAP is a non-parametric graph-based dimensionality reduction algorithm using applied Riemannian geometry and algebraic topology to find low-dimensional embeddings of structured data. The UMAP algorithm consists of two steps: (1) Compute a graphical representation of a dataset (fuzzy simplicial complex), and (2) Through stochastic gradient descent, optimize a low-dimensional embedding of the graph. Here, we replace the second step of UMAP with a deep neural network that learns a parametric relationship between data and embedding. We demonstrate that our method performs similarly to its non-parametric counterpart while conferring the benefit of a learned parametric mapping (e.g. fast online embeddings for new data). We then show that UMAP loss can be extended to arbitrary deep learning applications, for example constraining the latent distribution of autoencoders, and improving classifier accuracy for semi-supervised learning by capturing structure in unlabeled data. Our code is available at https://github.com/timsainb/ParametricUMAP_paper.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">New paper &quot;Parametric UMAP: learning embeddings with deep neural networks for representation and semi-supervised learning&quot; with <a href="https://twitter.com/leland_mcinnes?ref_src=twsrc%5Etfw">@leland_mcinnes</a> and <a href="https://twitter.com/TqGentner?ref_src=twsrc%5Etfw">@TqGentner</a>! 1/<a href="https://t.co/2x5YTZPSXU">https://t.co/2x5YTZPSXU</a> <a href="https://t.co/WJ7ECE0DI4">pic.twitter.com/WJ7ECE0DI4</a></p>&mdash; Tim Sainburg (@tim_sainburg) <a href="https://twitter.com/tim_sainburg/status/1310975420271980551?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. EvolGAN: Evolutionary Generative Adversarial Networks

Baptiste Roziere, Fabien Teytaud, Vlad Hosu, Hanhe Lin, Jeremy Rapin, Mariia Zameshina, Olivier Teytaud

- retweets: 484, favorites: 108 (09/30/2020 09:24:37)

- links: [abs](https://arxiv.org/abs/2009.13311) | [pdf](https://arxiv.org/pdf/2009.13311)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

We propose to use a quality estimator and evolutionary methods to search the latent space of generative adversarial networks trained on small, difficult datasets, or both. The new method leads to the generation of significantly higher quality images while preserving the original generator's diversity. Human raters preferred an image from the new version with frequency 83.7pc for Cats, 74pc for FashionGen, 70.4pc for Horses, and 69.2pc for Artworks, and minor improvements for the already excellent GANs for faces. This approach applies to any quality scorer and GAN generator.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">EvolGAN: Evolutionary Generative Adversarial Networks<br>pdf: <a href="https://t.co/pEewN8dy9v">https://t.co/pEewN8dy9v</a><br>abs: <a href="https://t.co/pY6czuphHE">https://t.co/pY6czuphHE</a> <a href="https://t.co/77A5uZ08h3">pic.twitter.com/77A5uZ08h3</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1310772052186542081?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval

Wenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei Du, Patrick Lewis, William Yang Wang, Yashar Mehdad, Wen-tau Yih, Sebastian Riedel, Douwe Kiela, Barlas Oƒüuz

- retweets: 399, favorites: 143 (09/30/2020 09:24:37)

- links: [abs](https://arxiv.org/abs/2009.12756) | [pdf](https://arxiv.org/pdf/2009.12756)
- [cs.CL](https://arxiv.org/list/cs.CL/recent)

We propose a simple and efficient multi-hop dense retrieval approach for answering complex open-domain questions, which achieves state-of-the-art performance on two multi-hop datasets, HotpotQA and multi-evidence FEVER. Contrary to previous work, our method does not require access to any corpus-specific information, such as inter-document hyperlinks or human-annotated entity markers, and can be applied to any unstructured text corpus. Our system also yields a much better efficiency-accuracy trade-off, matching the best published accuracy on HotpotQA while being 10 times faster at inference time.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval<br><br>Achieves the SOTA performance-computes trade-off in multi-hop open-domain QA (better than FiD). Best published accuracy on HotpotQA w/ 10x faster inference.<a href="https://t.co/o5aOrMLH4A">https://t.co/o5aOrMLH4A</a> <a href="https://t.co/dck9Cc1Ym1">pic.twitter.com/dck9Cc1Ym1</a></p>&mdash; Aran Komatsuzaki (@arankomatsuzaki) <a href="https://twitter.com/arankomatsuzaki/status/1310760510707515397?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üòâHappy to share our work on multi-hop (open-domain) QA (<a href="https://t.co/7BhmCqX64m">https://t.co/7BhmCqX64m</a>).  TL;DR: you don&#39;t need the Wikipedia hyperlinks to achieve SoTA performance on HotpotQA(<a href="https://twitter.com/qi2peng2?ref_src=twsrc%5Etfw">@qi2peng2</a> )! A shared RoBERTa encoder (for both Q and docs) is all you need to retrieve SP passages! 1/3 <a href="https://t.co/B9JO85Vd1l">pic.twitter.com/B9JO85Vd1l</a></p>&mdash; Wenhan Xiong (@xwhan_) <a href="https://twitter.com/xwhan_/status/1311005787406229504?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. A Diagnostic Study of Explainability Techniques for Text Classification

Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma, Isabelle Augenstein

- retweets: 211, favorites: 160 (09/30/2020 09:24:37)

- links: [abs](https://arxiv.org/abs/2009.13295) | [pdf](https://arxiv.org/pdf/2009.13295)
- [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

Recent developments in machine learning have introduced models that approach human performance at the cost of increased architectural complexity. Efforts to make the rationales behind the models' predictions transparent have inspired an abundance of new explainability techniques. Provided with an already trained model, they compute saliency scores for the words of an input instance. However, there exists no definitive guide on (i) how to choose such a technique given a particular application task and model architecture, and (ii) the benefits and drawbacks of using each such technique. In this paper, we develop a comprehensive list of diagnostic properties for evaluating existing explainability techniques. We then employ the proposed list to compare a set of diverse explainability techniques on downstream text classification tasks and neural network architectures. We also compare the saliency scores assigned by the explainability techniques with human annotations of salient input regions to find relations between a model's performance and the agreement of its rationales with human ones. Overall, we find that the gradient-based explanations perform best across tasks and model architectures, and we present further insights into the properties of the reviewed explainability techniques.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">When an NLP model makes a prediction, to what degree did each input token contribute towards making that prediction?<a href="https://twitter.com/atanasovapepa?ref_src=twsrc%5Etfw">@atanasovapepa</a> <a href="https://twitter.com/IAugenstein?ref_src=twsrc%5Etfw">@IAugenstein</a> compare various explainability techniques (for different models and on different datasets) in <a href="https://t.co/fIT9uF8tSP">https://t.co/fIT9uF8tSP</a> <a href="https://twitter.com/hashtag/emnlp2020?src=hash&amp;ref_src=twsrc%5Etfw">#emnlp2020</a> <a href="https://t.co/mMsNdJX6P6">pic.twitter.com/mMsNdJX6P6</a></p>&mdash; Jay Alammar (@JayAlammar) <a href="https://twitter.com/JayAlammar/status/1310867953294942209?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A preprint of this <a href="https://twitter.com/hashtag/emnlp2020?src=hash&amp;ref_src=twsrc%5Etfw">#emnlp2020</a> paper by <a href="https://twitter.com/atanasovapepa?ref_src=twsrc%5Etfw">@atanasovapepa</a> et al. is now available: <a href="https://t.co/l5fuq8qJQw">https://t.co/l5fuq8qJQw</a><a href="https://twitter.com/hashtag/XAI?src=hash&amp;ref_src=twsrc%5Etfw">#XAI</a> <a href="https://twitter.com/hashtag/ML?src=hash&amp;ref_src=twsrc%5Etfw">#ML</a> <a href="https://twitter.com/hashtag/NLProc?src=hash&amp;ref_src=twsrc%5Etfw">#NLProc</a> <a href="https://t.co/vhgWXsmQ6F">https://t.co/vhgWXsmQ6F</a></p>&mdash; Isabelle Augenstein (@IAugenstein) <a href="https://twitter.com/IAugenstein/status/1310851220404346886?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. Normalization Techniques in Training DNNs: Methodology, Analysis and  Application

Lei Huang, Jie Qin, Yi Zhou, Fan Zhu, Li Liu, Ling Shao

- retweets: 272, favorites: 84 (09/30/2020 09:24:38)

- links: [abs](https://arxiv.org/abs/2009.12836) | [pdf](https://arxiv.org/pdf/2009.12836)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.CV](https://arxiv.org/list/cs.CV/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

Normalization techniques are essential for accelerating the training and improving the generalization of deep neural networks (DNNs), and have successfully been used in various applications. This paper reviews and comments on the past, present and future of normalization methods in the context of DNN training. We provide a unified picture of the main motivation behind different approaches from the perspective of optimization, and present a taxonomy for understanding the similarities and differences between them. Specifically, we decompose the pipeline of the most representative normalizing activation methods into three components: the normalization area partitioning, normalization operation and normalization representation recovery. In doing so, we provide insight for designing new normalization technique. Finally, we discuss the current progress in understanding normalization methods, and provide a comprehensive review of the applications of normalization for particular tasks, in which it can effectively solve the key issues.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Normalization Techniques in Training DNNs:<br>Methodology, Analysis and Application<a href="https://t.co/wNzCQT1dUB">https://t.co/wNzCQT1dUB</a> <a href="https://t.co/GIiLYeKuBs">pic.twitter.com/GIiLYeKuBs</a></p>&mdash; phalanx (@ZFPhalanx) <a href="https://twitter.com/ZFPhalanx/status/1310786753666588672?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a  Survey

Wenshuai Zhao, Jorge Pe√±a Queralta, Tomi Westerlund

- retweets: 225, favorites: 71 (09/30/2020 09:24:38)

- links: [abs](https://arxiv.org/abs/2009.13303) | [pdf](https://arxiv.org/pdf/2009.13303)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.RO](https://arxiv.org/list/cs.RO/recent)

Deep reinforcement learning has recently seen huge success across multiple areas in the robotics domain. Owing to the limitations of gathering real-world data, i.e., sample inefficiency and the cost of collecting it, simulation environments are utilized for training the different agents. This not only aids in providing a potentially infinite data source, but also alleviates safety concerns with real robots. Nonetheless, the gap between the simulated and real worlds degrades the performance of the policies once the models are transferred into real robots. Multiple research efforts are therefore now being directed towards closing this sim-to-real gap and accomplish more efficient policy transfer. Recent years have seen the emergence of multiple methods applicable to different domains, but there is a lack, to the best of our knowledge, of a comprehensive review summarizing and putting into context the different methods. In this survey paper, we cover the fundamental background behind sim-to-real transfer in deep reinforcement learning and overview the main methods being utilized at the moment: domain randomization, domain adaptation, imitation learning, meta-learning and knowledge distillation. We categorize some of the most relevant recent works, and outline the main application scenarios. Finally, we discuss the main opportunities and challenges of the different approaches and point to the most promising directions.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey<a href="https://t.co/DRUQ8Y1LgZ">https://t.co/DRUQ8Y1LgZ</a> <a href="https://t.co/vkkPu27vYH">pic.twitter.com/vkkPu27vYH</a></p>&mdash; sim2real (@sim2realAIorg) <a href="https://twitter.com/sim2realAIorg/status/1310753652819111936?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. Texture Memory-Augmented Deep Patch-Based Image Inpainting

Rui Xu, Minghao Guo, Jiaqi Wang, Xiaoxiao Li, Bolei Zhou, Chen Change Loy

- retweets: 132, favorites: 59 (09/30/2020 09:24:38)

- links: [abs](https://arxiv.org/abs/2009.13240) | [pdf](https://arxiv.org/pdf/2009.13240)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [eess.IV](https://arxiv.org/list/eess.IV/recent)

Patch-based methods and deep networks have been employed to tackle image inpainting problem, with their own strengths and weaknesses. Patch-based methods are capable of restoring a missing region with high-quality texture through searching nearest neighbor patches from the unmasked regions. However, these methods bring problematic contents when recovering large missing regions. Deep networks, on the other hand, show promising results in completing large regions. Nonetheless, the results often lack faithful and sharp details that resemble the surrounding area. By bringing together the best of both paradigms, we propose a new deep inpainting framework where texture generation is guided by a texture memory of patch samples extracted from unmasked regions. The framework has a novel design that allows texture memory retrieval to be trained end-to-end with the deep inpainting network. In addition, we introduce a patch distribution loss to encourage high-quality patch synthesis. The proposed method shows superior performance both qualitatively and quantitatively on three challenging image benchmarks, i.e., Places, CelebA-HQ, and Paris Street-View datasets.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Texture Memory-Augmented Deep Patch-Based Image Inpainting<br>pdf: <a href="https://t.co/hT0SJScW1s">https://t.co/hT0SJScW1s</a><br>abs: <a href="https://t.co/be9R1hY9Xm">https://t.co/be9R1hY9Xm</a> <a href="https://t.co/JfkHIfz0Ow">pic.twitter.com/JfkHIfz0Ow</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1310810466558636037?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 8. Is Reinforcement Learning More Difficult Than Bandits? A Near-optimal  Algorithm Escaping the Curse of Horizon

Zihan Zhang, Xiangyang Ji, Simon S. Du

- retweets: 56, favorites: 75 (09/30/2020 09:24:38)

- links: [abs](https://arxiv.org/abs/2009.13503) | [pdf](https://arxiv.org/pdf/2009.13503)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

Episodic reinforcement learning and contextual bandits are two widely studied sequential decision-making problems. Episodic reinforcement learning generalizes contextual bandits and is often perceived to be more difficult due to long planning horizon and unknown state-dependent transitions. The current paper shows that the long planning horizon and the unknown state-dependent transitions (at most) pose little additional difficulty on sample complexity. We consider the episodic reinforcement learning with $S$ states, $A$ actions, planning horizon $H$, total reward bounded by $1$, and the agent plays for $K$ episodes. We propose a new algorithm, \textbf{M}onotonic \textbf{V}alue \textbf{P}ropagation (MVP), which relies on a new Bernstein-type bonus. The new bonus only requires tweaking the \emph{constants} to ensure optimism and thus is significantly simpler than existing bonus constructions. We show MVP enjoys an $O\left(\left(\sqrt{SAK} + S^2A\right) \text{poly}\log \left(SAHK\right)\right)$ regret, approaching the $\Omega\left(\sqrt{SAK}\right)$ lower bound of \emph{contextual bandits}. Notably, this result 1) \emph{exponentially} improves the state-of-the-art polynomial-time algorithms by Dann et al. [2019], Zanette et al. [2019] and Zhang et al. [2020] in terms of the dependency on $H$, and 2) \emph{exponentially} improves the running time in [Wang et al. 2020] and significantly improves the dependency on $S$, $A$ and $K$ in sample complexity.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Reinforcement Learning is a strict generalization of bandits due to long planning horizon and unknown transition, but is RL fundamentally harder? Our new algorithm for tabular RL, Monotonic Value Propogation (MVP), approaches the bandits&#39; lower bound!<a href="https://t.co/inwDpzSOQ1">https://t.co/inwDpzSOQ1</a> <a href="https://t.co/qk544zqfeV">pic.twitter.com/qk544zqfeV</a></p>&mdash; Simon Shaolei Du (@SimonShaoleiDu) <a href="https://twitter.com/SimonShaoleiDu/status/1310963990978162688?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. SceneGen: Generative Contextual Scene Augmentation using Scene Graph  Priors

Mohammad Keshavarzi, Aakash Parikh, Xiyu Zhai, Melody Mao, Luisa Caldas, Allen Yang

- retweets: 72, favorites: 49 (09/30/2020 09:24:38)

- links: [abs](https://arxiv.org/abs/2009.12395) | [pdf](https://arxiv.org/pdf/2009.12395)
- [cs.GR](https://arxiv.org/list/cs.GR/recent) | [cs.CV](https://arxiv.org/list/cs.CV/recent)

Spatial computing experiences are constrained by the real-world surroundings of the user. In such experiences, augmenting virtual objects to existing scenes require a contextual approach, where geometrical conflicts are avoided, and functional and plausible relationships to other objects are maintained in the target environment. Yet, due to the complexity and diversity of user environments, automatically calculating ideal positions of virtual content that is adaptive to the context of the scene is considered a challenging task. Motivated by this problem, in this paper we introduce SceneGen, a generative contextual augmentation framework that predicts virtual object positions and orientations within existing scenes. SceneGen takes a semantically segmented scene as input, and outputs positional and orientational probability maps for placing virtual content. We formulate a novel spatial Scene Graph representation, which encapsulates explicit topological properties between objects, object groups, and the room. We believe providing explicit and intuitive features plays an important role in informative content creation and user interaction of spatial computing settings, a quality that is not captured in implicit models. We use kernel density estimation (KDE) to build a multivariate conditional knowledge model trained using prior spatial Scene Graphs extracted from real-world 3D scanned data. To further capture orientational properties, we develop a fast pose annotation tool to extend current real-world datasets with orientational labels. Finally, to demonstrate our system in action, we develop an Augmented Reality application, in which objects can be contextually augmented in real-time.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">SceneGen is a framework to place virtual objects in a target scene. The placement is guided by the generative model that captures functional and topological relationships learned from real-world datasets.<a href="https://t.co/druyXewJta">https://t.co/druyXewJta</a> <a href="https://t.co/4VATxNXBo1">pic.twitter.com/4VATxNXBo1</a></p>&mdash; Ankur Handa (@ankurhandos) <a href="https://twitter.com/ankurhandos/status/1310970261835972617?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">SceneGen: Generative Contextual Scene Augmentation using Scene Graph Priors<br>pdf: <a href="https://t.co/fLaNd6rdWK">https://t.co/fLaNd6rdWK</a><br>abs: <a href="https://t.co/B3zVCsk0se">https://t.co/B3zVCsk0se</a> <a href="https://t.co/4kb2lxIot1">pic.twitter.com/4kb2lxIot1</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1310748348635373569?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 10. COVID-19's (mis)information ecosystem on Twitter: How partisanship  boosts the spread of conspiracy narratives on German speaking Twitter

Morteza Shahrezaye, Miriam Meckel, L√©a Steinacker, Viktor Suter

- retweets: 70, favorites: 34 (09/30/2020 09:24:38)

- links: [abs](https://arxiv.org/abs/2009.12905) | [pdf](https://arxiv.org/pdf/2009.12905)
- [cs.SI](https://arxiv.org/list/cs.SI/recent)

In late 2019, the gravest pandemic in a century began spreading across the world. A state of uncertainty related to what has become known as SARS-CoV-2 has since fueled conspiracy narratives on social media about the origin, transmission and medical treatment of and vaccination against the resulting disease, COVID-19. Using social media intelligence to monitor and understand the proliferation of conspiracy narratives is one way to analyze the distribution of misinformation on the pandemic. We analyzed more than 9.5M German language tweets about COVID-19. The results show that only about 0.6% of all those tweets deal with conspiracy theory narratives. We also found that the political orientation of users correlates with the volume of content users contribute to the dissemination of conspiracy narratives, implying that partisan communicators have a higher motivation to take part in conspiratorial discussions on Twitter. Finally, we showed that contrary to other studies, automated accounts do not significantly influence the spread of misinformation in the German speaking Twitter sphere. They only represent about 1.31% of all conspiracy-related activities in our database.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">In our new paper on the spread of COVID-19 misinformation on üá©üá™-Twitter we show that  <br><br>üî∏partisan accounts contribute relatively more to conspiratorial narratives<br><br>üî∏bots don&#39;t significantly influence the spread of misinformation in üá©üá™-Twitter (1.31%)<a href="https://t.co/Ih8B2tJFwb">https://t.co/Ih8B2tJFwb</a> <a href="https://t.co/hBLBZcoZCd">pic.twitter.com/hBLBZcoZCd</a></p>&mdash; L√©a Steinacker (@leasteinacker) <a href="https://twitter.com/leasteinacker/status/1310877005072736257?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 11. Operads for Designing Systems of Systems

John C. Baez, John Foley

- retweets: 72, favorites: 26 (09/30/2020 09:24:39)

- links: [abs](https://arxiv.org/abs/2009.12647) | [pdf](https://arxiv.org/pdf/2009.12647)
- [cs.SE](https://arxiv.org/list/cs.SE/recent) | [math.CT](https://arxiv.org/list/math.CT/recent)

System of systems engineering seeks to analyze, design and deploy collections of systems that together can flexibly address an array of complex tasks. In the Complex Adaptive System Composition and Design Environment program, we developed "network operads" as a tool for designing and tasking systems of systems, and applied them to domains including maritime search and rescue. The network operad formalism offers new ways to handle changing levels of abstraction in system-of-system design and tasking.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://t.co/PFW5M1MYJs">https://t.co/PFW5M1MYJs</a> (2 page extended abstract) <a href="https://t.co/yoEBINJYTe">pic.twitter.com/yoEBINJYTe</a></p>&mdash; julesh (@_julesh_) <a href="https://twitter.com/_julesh_/status/1310931639837523968?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 12. Deep Transformers with Latent Depth

Xian Li, Asa Cooper Stickland, Yuqing Tang, Xiang Kong

- retweets: 36, favorites: 50 (09/30/2020 09:24:39)

- links: [abs](https://arxiv.org/abs/2009.13102) | [pdf](https://arxiv.org/pdf/2009.13102)
- [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

The Transformer model has achieved state-of-the-art performance in many sequence modeling tasks. However, how to leverage model capacity with large or variable depths is still an open challenge. We present a probabilistic framework to automatically learn which layer(s) to use by learning the posterior distributions of layer selection. As an extension of this framework, we propose a novel method to train one shared Transformer network for multilingual machine translation with different layer selection posteriors for each language pair. The proposed method alleviates the vanishing gradient issue and enables stable training of deep Transformers (e.g. 100 layers). We evaluate on WMT English-German machine translation and masked language modeling tasks, where our method outperforms existing approaches for training deeper Transformers. Experiments on multilingual machine translation demonstrate that this approach can effectively leverage increased model capacity and bring universal improvement for both many-to-one and one-to-many translation with diverse language pairs.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Deep Transformers with Latent Depth<br><br>Depth-adaptive conditional computation of Transformers. Improves performance-computes trade-off on multilingual translation and MLM. <a href="https://t.co/9dewhvQGJF">https://t.co/9dewhvQGJF</a> <a href="https://t.co/zBmfj9kNJv">pic.twitter.com/zBmfj9kNJv</a></p>&mdash; Aran Komatsuzaki (@arankomatsuzaki) <a href="https://twitter.com/arankomatsuzaki/status/1310765801805283329?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 13. Dissecting Lottery Ticket Transformers: Structural and Behavioral Study  of Sparse Neural Machine Translation

Rajiv Movva, Jason Y. Zhao

- retweets: 44, favorites: 39 (09/30/2020 09:24:39)

- links: [abs](https://arxiv.org/abs/2009.13270) | [pdf](https://arxiv.org/pdf/2009.13270)
- [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

Recent work on the lottery ticket hypothesis has produced highly sparse Transformers for NMT while maintaining BLEU. However, it is unclear how such pruning techniques affect a model's learned representations. By probing sparse Transformers, we find that complex semantic information is first to be degraded. Analysis of internal activations reveals that higher layers diverge most over the course of pruning, gradually becoming less complex than their dense counterparts. Meanwhile, early layers of sparse models begin to perform more encoding. Attention mechanisms remain remarkably consistent as sparsity increases.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our paper ‚ÄúDissecting Lottery Ticket Transformers: Structural and Behavioral Study of Sparse Neural Machine Translation‚Äù is accepted to BlackboxNLP 2020 (at EMNLP this year)! arXiv link: <a href="https://t.co/XOX6ZHKWUD">https://t.co/XOX6ZHKWUD</a>. Brief summary to follow: 1/15</p>&mdash; Raj Movva (@rajivmovva) <a href="https://twitter.com/rajivmovva/status/1311017289500766208?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 14. Semi-Supervised Learning for In-Game Expert-Level Music-to-Dance  Translation

Yinglin Duan, Tianyang Shi, Zhengxia Zou, Jia Qin, Yifei Zhao, Yi Yuan, Jie Hou, Xiang Wen, Changjie Fan

- retweets: 36, favorites: 21 (09/30/2020 09:24:39)

- links: [abs](https://arxiv.org/abs/2009.12763) | [pdf](https://arxiv.org/pdf/2009.12763)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.MM](https://arxiv.org/list/cs.MM/recent)

Music-to-dance translation is a brand-new and powerful feature in recent role-playing games. Players can now let their characters dance along with specified music clips and even generate fan-made dance videos. Previous works of this topic consider music-to-dance as a supervised motion generation problem based on time-series data. However, these methods suffer from limited training data pairs and the degradation of movements. This paper provides a new perspective for this task where we re-formulate the translation problem as a piece-wise dance phrase retrieval problem based on the choreography theory. With such a design, players are allowed to further edit the dance movements on top of our generation while other regression based methods ignore such user interactivity. Considering that the dance motion capture is an expensive and time-consuming procedure which requires the assistance of professional dancers, we train our method under a semi-supervised learning framework with a large unlabeled dataset (20x than labeled data) collected. A co-ascent mechanism is introduced to improve the robustness of our network. Using this unlabeled dataset, we also introduce self-supervised pre-training so that the translator can understand the melody, rhythm, and other components of music phrases. We show that the pre-training significantly improves the translation accuracy than that of training from scratch. Experimental results suggest that our method not only generalizes well over various styles of music but also succeeds in expert-level choreography for game players.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Semi-Supervised Learning for In-Game Expert-Level Music-to-Dance Translation<br>pdf: <a href="https://t.co/orathZ9c9i">https://t.co/orathZ9c9i</a><br>abs: <a href="https://t.co/ID3dLih2Ps">https://t.co/ID3dLih2Ps</a> <a href="https://t.co/sK08JhHnoo">pic.twitter.com/sK08JhHnoo</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1310755375747084288?ref_src=twsrc%5Etfw">September 29, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



