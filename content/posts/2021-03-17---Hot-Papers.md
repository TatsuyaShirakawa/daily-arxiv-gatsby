---
title: Hot Papers 2021-03-17
date: 2021-03-18T09:55:38.Z
template: "post"
draft: false
slug: "hot-papers-2021-03-17"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2021-03-17"
socialImage: "/media/flying-marine.jpg"

---

# 1. Growing 3D Artefacts and Functional Machines with Neural Cellular  Automata

Shyam Sudhakaran, Djordje Grbic, Siyan Li, Adam Katona, Elias Najarro, Claire Glanois, Sebastian Risi

- retweets: 10889, favorites: 134 (03/18/2021 09:55:38)

- links: [abs](https://arxiv.org/abs/2103.08737) | [pdf](https://arxiv.org/pdf/2103.08737)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)

Neural Cellular Automata (NCAs) have been proven effective in simulating morphogenetic processes, the continuous construction of complex structures from very few starting cells. Recent developments in NCAs lie in the 2D domain, namely reconstructing target images from a single pixel or infinitely growing 2D textures. In this work, we propose an extension of NCAs to 3D, utilizing 3D convolutions in the proposed neural network architecture. Minecraft is selected as the environment for our automaton since it allows the generation of both static structures and moving machines. We show that despite their simplicity, NCAs are capable of growing complex entities such as castles, apartment blocks, and trees, some of which are composed of over 3,000 blocks. Additionally, when trained for regeneration, the system is able to regrow parts of simple functional machines, significantly expanding the capabilities of simulated morphogenetic systems.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Growing 3D Artefacts and Functional Machines with Neural Cellular Automata<br><br>They use Neural CA to generate moving creatures in Minecraft. When they&#39;re cut into pieces, each piece has the ability to regenerate into a fully formed creature. Super cool work!<a href="https://t.co/Z1vjX0kvdt">https://t.co/Z1vjX0kvdt</a> <a href="https://t.co/tXWe3x1bLo">https://t.co/tXWe3x1bLo</a></p>&mdash; hardmaru (@hardmaru) <a href="https://twitter.com/hardmaru/status/1372178963485786116?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Excited to share our work on Morphogenesis in Minecraft! We show that neural cellular automata can learn to grow not only complex 3D artifacts with over 3,000 blocks but also functional Minecraft machines that can regenerate when cut in half üêõüî™=üêõüêõ<br><br>PDF:<a href="https://t.co/hi573xzWIG">https://t.co/hi573xzWIG</a> <a href="https://t.co/m19572pcIe">pic.twitter.com/m19572pcIe</a></p>&mdash; Sebastian Risi (@risi1979) <a href="https://twitter.com/risi1979/status/1372158321256456198?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. Back to the Feature: Learning Robust Camera Localization from Pixels to  Pose

Paul-Edouard Sarlin, Ajaykumar Unagar, M√•ns Larsson, Hugo Germain, Carl Toft, Viktor Larsson, Marc Pollefeys, Vincent Lepetit, Lars Hammarstrand, Fredrik Kahl, Torsten Sattler

- retweets: 2937, favorites: 438 (03/18/2021 09:55:39)

- links: [abs](https://arxiv.org/abs/2103.09213) | [pdf](https://arxiv.org/pdf/2103.09213)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)

Camera pose estimation in known scenes is a 3D geometry task recently tackled by multiple learning algorithms. Many regress precise geometric quantities, like poses or 3D points, from an input image. This either fails to generalize to new viewpoints or ties the model parameters to a specific scene. In this paper, we go Back to the Feature: we argue that deep networks should focus on learning robust and invariant visual features, while the geometric estimation should be left to principled algorithms. We introduce PixLoc, a scene-agnostic neural network that estimates an accurate 6-DoF pose from an image and a 3D model. Our approach is based on the direct alignment of multiscale deep features, casting camera localization as metric learning. PixLoc learns strong data priors by end-to-end training from pixels to pose and exhibits exceptional generalization to new scenes by separating model parameters and scene geometry. The system can localize in large environments given coarse pose priors but also improve the accuracy of sparse feature matching by jointly refining keypoints and poses with little overhead. The code will be publicly available at https://github.com/cvg/pixloc.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Back to the Feature: Learning Robust Camera Localization from Pixels to Pose<br><br>This paper is based on the alignment of deep multiscale features and combines the best of deep learning with multiview geometry. Checkout those learned heatmaps!<a href="https://t.co/JQXvvSEdgF">https://t.co/JQXvvSEdgF</a> <a href="https://twitter.com/hashtag/computervision?src=hash&amp;ref_src=twsrc%5Etfw">#computervision</a> <a href="https://t.co/NsRC36DK6t">pic.twitter.com/NsRC36DK6t</a></p>&mdash; Tomasz Malisiewicz (@quantombone) <a href="https://twitter.com/quantombone/status/1372018158417158149?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Back to the Feature: Learning Robust Camera Localization from Pixels to Pose<br>pdf: <a href="https://t.co/Vj51BlgvY7">https://t.co/Vj51BlgvY7</a><br>abs: <a href="https://t.co/jmOSZyNJr5">https://t.co/jmOSZyNJr5</a> <a href="https://t.co/eWlTtHsLk4">pic.twitter.com/eWlTtHsLk4</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1371997303146430465?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Back to the Feature: Learning Robust Camera Localization from Pixels to Pose<a href="https://twitter.com/pesarlin?ref_src=twsrc%5Etfw">@pesarlin</a> + 10 authors<a href="https://t.co/7OEOyvfYhd">https://t.co/7OEOyvfYhd</a><br><br>Main idea: roughly good (R,t) is all you need. The rest can be obtained from the alignment of the deep features. <a href="https://t.co/XkHhzGzTdw">pic.twitter.com/XkHhzGzTdw</a></p>&mdash; Dmytro Mishkin (@ducha_aiki) <a href="https://twitter.com/ducha_aiki/status/1372144074581495808?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. Is it Enough to Optimize CNN Architectures on ImageNet?

Lukas Tuggener, J√ºrgen Schmidhuber, Thilo Stadelmann

- retweets: 570, favorites: 196 (03/18/2021 09:55:40)

- links: [abs](https://arxiv.org/abs/2103.09108) | [pdf](https://arxiv.org/pdf/2103.09108)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

An implicit but pervasive hypothesis of modern computer vision research is that convolutional neural network (CNN) architectures that perform better on ImageNet will also perform better on other vision datasets. We challenge this hypothesis through an extensive empirical study for which we train 500 sampled CNN architectures on ImageNet as well as 8 other image classification datasets from a wide array of application domains. The relationship between architecture and performance varies wildly, depending on the datasets. For some of them, the performance correlation with ImageNet is even negative. Clearly, it is not enough to optimize architectures solely for ImageNet when aiming for progress that is relevant for all applications. Therefore, we identify two dataset-specific performance indicators: the cumulative width across layers as well as the total depth of the network. Lastly, we show that the range of dataset variability covered by ImageNet can be significantly extended by adding ImageNet subsets restricted to few classes.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Is it Enough to Optimize CNN Architectures on ImageNet?<br><br>The relationship between architecture and performance varies wildly, depending on the datasets. For some of them the performance correlation with ImageNet is even negative.<a href="https://t.co/WLdQl3HprY">https://t.co/WLdQl3HprY</a> <a href="https://t.co/LooMfCIRY5">pic.twitter.com/LooMfCIRY5</a></p>&mdash; Aran Komatsuzaki (@arankomatsuzaki) <a href="https://twitter.com/arankomatsuzaki/status/1371990301674409986?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Is it Enough to Optimize CNN Architectures on ImageNet?<br>pdf: <a href="https://t.co/zC5jToLTto">https://t.co/zC5jToLTto</a><br>abs: <a href="https://t.co/oIYWstLrIf">https://t.co/oIYWstLrIf</a> <a href="https://t.co/RrEHLNJEqa">pic.twitter.com/RrEHLNJEqa</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1372006835977388034?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. Autonomous Drone Racing with Deep Reinforcement Learning

Yunlong Song, Mats Steinweg, Elia Kaufmann, Davide Scaramuzza

- retweets: 380, favorites: 76 (03/18/2021 09:55:40)

- links: [abs](https://arxiv.org/abs/2103.08624) | [pdf](https://arxiv.org/pdf/2103.08624)
- [cs.RO](https://arxiv.org/list/cs.RO/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)

In many robotic tasks, such as drone racing, the goal is to travel through a set of waypoints as fast as possible. A key challenge for this task is planning the minimum-time trajectory, which is typically solved by assuming perfect knowledge of the waypoints to pass in advance. The resulting solutions are either highly specialized for a single-track layout, or suboptimal due to simplifying assumptions about the platform dynamics. In this work, a new approach to minimum-time trajectory generation for quadrotors is presented. Leveraging deep reinforcement learning and relative gate observations, this approach can adaptively compute near-time-optimal trajectories for random track layouts. Our method exhibits a significant computational advantage over approaches based on trajectory optimization for non-trivial track configurations. The proposed approach is evaluated on a set of race tracks in simulation and the real world, achieving speeds of up to 17 m/s with a physical quadrotor.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Autonomous Drone Racing with Deep Reinforcement Learning<br>pdf: <a href="https://t.co/sZeU9pcRTL">https://t.co/sZeU9pcRTL</a><br>abs: <a href="https://t.co/rnHLQPEoPw">https://t.co/rnHLQPEoPw</a> <a href="https://t.co/ZnyhUapzca">pic.twitter.com/ZnyhUapzca</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1371994089135169540?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. Deep learning: a statistical viewpoint

Peter L. Bartlett, Andrea Montanari, Alexander Rakhlin

- retweets: 92, favorites: 68 (03/18/2021 09:55:40)

- links: [abs](https://arxiv.org/abs/2103.09177) | [pdf](https://arxiv.org/pdf/2103.09177)
- [math.ST](https://arxiv.org/list/math.ST/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

The remarkable practical success of deep learning has revealed some major surprises from a theoretical perspective. In particular, simple gradient methods easily find near-optimal solutions to non-convex optimization problems, and despite giving a near-perfect fit to training data without any explicit effort to control model complexity, these methods exhibit excellent predictive accuracy. We conjecture that specific principles underlie these phenomena: that overparametrization allows gradient methods to find interpolating solutions, that these methods implicitly impose regularization, and that overparametrization leads to benign overfitting. We survey recent theoretical progress that provides examples illustrating these principles in simpler settings. We first review classical uniform convergence results and why they fall short of explaining aspects of the behavior of deep learning methods. We give examples of implicit regularization in simple settings, where gradient methods lead to minimal norm functions that perfectly fit the training data. Then we review prediction methods that exhibit benign overfitting, focusing on regression problems with quadratic loss. For these methods, we can decompose the prediction rule into a simple component that is useful for prediction and a spiky component that is useful for overfitting but, in a favorable setting, does not harm prediction accuracy. We focus specifically on the linear regime for neural networks, where the network can be approximated by a linear model. In this regime, we demonstrate the success of gradient flow, and we consider benign overfitting with two-layer networks, giving an exact asymptotic analysis that precisely demonstrates the impact of overparametrization. We conclude by highlighting the key challenges that arise in extending these insights to realistic deep learning settings.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Peter L. Bartlett, Andrea Montanari, Alexander Rakhlin: Deep learning: a statistical viewpoint <a href="https://t.co/0CNfVp4BcI">https://t.co/0CNfVp4BcI</a> <a href="https://t.co/lBmGKZEygZ">https://t.co/lBmGKZEygZ</a></p>&mdash; arXiv math.ST Statistics Theory (@mathSTb) <a href="https://twitter.com/mathSTb/status/1372011842617286661?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. Fast Development of ASR in African Languages using Self Supervised  Speech Representation Learning

Jama Hussein Mohamud, Lloyd Acquaye Thompson, Aissatou Ndoye, Laurent Besacier

- retweets: 92, favorites: 59 (03/18/2021 09:55:40)

- links: [abs](https://arxiv.org/abs/2103.08993) | [pdf](https://arxiv.org/pdf/2103.08993)
- [cs.SD](https://arxiv.org/list/cs.SD/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent) | [eess.AS](https://arxiv.org/list/eess.AS/recent)

This paper describes the results of an informal collaboration launched during the African Master of Machine Intelligence (AMMI) in June 2020. After a series of lectures and labs on speech data collection using mobile applications and on self-supervised representation learning from speech, a small group of students and the lecturer continued working on automatic speech recognition (ASR) project for three languages: Wolof, Ga, and Somali. This paper describes how data was collected and ASR systems developed with a small amount (1h) of transcribed speech as training data. In these low resource conditions, pre-training a model on large amounts of raw speech was fundamental for the efficiency of ASR systems developed.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">An informal collab. during 2020 African Master of Machine Intelligence (AMMI) lead to this paper on ASR for Wolof, Ga, and Somali. We leveraged self supervised speech representation learning to train with only 1h of  transcribed speech<a href="https://t.co/Wxa2PUM0N2">https://t.co/Wxa2PUM0N2</a></p>&mdash; laurent besacier (@laurent_besacie) <a href="https://twitter.com/laurent_besacie/status/1372082838854586372?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. A Systematic Literature Review and Taxonomy of Modern Code Review

Nicole Davila, Ingrid Nunes

- retweets: 81, favorites: 28 (03/18/2021 09:55:40)

- links: [abs](https://arxiv.org/abs/2103.08777) | [pdf](https://arxiv.org/pdf/2103.08777)
- [cs.SE](https://arxiv.org/list/cs.SE/recent)

Modern Code Review (MCR) is a widely known practice of software quality assurance. However, the existing body of knowledge of MCR is currently not understood as a whole. Objective: Our goal is to identify the state of the art on MCR, providing a structured overview and an in-depth analysis of the research done in this field. Method: We performed a systematic literature review, selecting publications from four digital libraries. Results: A total of 139 papers were selected and analyzed in three main categories. Foundational studies are those that analyze existing or collected data from the adoption of MCR. Proposals consist of techniques and tools to support MCR, while evaluations are studies to assess an approach or compare a set of them. Conclusion: The most represented category is foundational studies, mainly aiming to understand the motivations for adopting MCR, its challenges and benefits, and which influence factors lead to which MCR outcomes. The most common types of proposals are code reviewer recommender and support to code checking. Evaluations of MCR-supporting approaches have been done mostly offline, without involving human subjects. Five main research gaps have been identified, which point out directions for future work in the area.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Lots of papers on <a href="https://twitter.com/hashtag/CodeReview?src=hash&amp;ref_src=twsrc%5Etfw">#CodeReview</a> were published. But what do we know? What makes code review effective? What kind of support does science provide? See the answers to these questions in our paper (with <a href="https://twitter.com/nicoleNCD?ref_src=twsrc%5Etfw">@nicoleNCD</a>) accepted by <a href="https://twitter.com/JSSoftware?ref_src=twsrc%5Etfw">@JSSoftware</a>: <br><br>Preprint: <a href="https://t.co/O41QffvKwx">https://t.co/O41QffvKwx</a></p>&mdash; Ingrid Nunes (@ingridnunesIN) <a href="https://twitter.com/ingridnunesIN/status/1372183506114199553?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 8. Spatial Dependency Networks: Neural Layers for Improved Generative Image  Modeling

ƒêorƒëe Miladinoviƒá, Aleksandar Staniƒá, Stefan Bauer, J√ºrgen Schmidhuber, Joachim M. Buhmann

- retweets: 34, favorites: 64 (03/18/2021 09:55:41)

- links: [abs](https://arxiv.org/abs/2103.08877) | [pdf](https://arxiv.org/pdf/2103.08877)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

How to improve generative modeling by better exploiting spatial regularities and coherence in images? We introduce a novel neural network for building image generators (decoders) and apply it to variational autoencoders (VAEs). In our spatial dependency networks (SDNs), feature maps at each level of a deep neural net are computed in a spatially coherent way, using a sequential gating-based mechanism that distributes contextual information across 2-D space. We show that augmenting the decoder of a hierarchical VAE by spatial dependency layers considerably improves density estimation over baseline convolutional architectures and the state-of-the-art among the models within the same class. Furthermore, we demonstrate that SDN can be applied to large images by synthesizing samples of high quality and coherence. In a vanilla VAE setting, we find that a powerful SDN decoder also improves learning disentangled representations, indicating that neural architectures play an important role in this task. Our results suggest favoring spatial dependency over convolutional layers in various VAE settings. The accompanying source code is given at https://github.com/djordjemila/sdn.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Spatial Dependency Networks: Neural Layers for Improved Generative Image Modeling<br>pdf: <a href="https://t.co/vo8UnnmneG">https://t.co/vo8UnnmneG</a><br>abs: <a href="https://t.co/KxGX5CsgTN">https://t.co/KxGX5CsgTN</a><br>github: <a href="https://t.co/YxzwQpTTQo">https://t.co/YxzwQpTTQo</a> <a href="https://t.co/jyzybfvEfb">pic.twitter.com/jyzybfvEfb</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1371985366325075968?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Spatial Dependency Networks: Neural Layers for Improved Generative Image Modeling<br><br>Achieves nearly SotA NLL in image modeling by augmenting the decoder of a hierarchical VAE by spatial dependency layers.<br><br>abs: <a href="https://t.co/nsg2DgR7pd">https://t.co/nsg2DgR7pd</a><br>github: <a href="https://t.co/CD5hB7O28g">https://t.co/CD5hB7O28g</a></p>&mdash; Aran Komatsuzaki (@arankomatsuzaki) <a href="https://twitter.com/arankomatsuzaki/status/1371991360035647490?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. Understanding the Representation and Representativeness of Age in AI  Data Sets

Joon Sung Park, Michael S. Bernstein, Robin N. Brewer, Ece Kamar, Meredith Ringel Morris

- retweets: 72, favorites: 18 (03/18/2021 09:55:41)

- links: [abs](https://arxiv.org/abs/2103.09058) | [pdf](https://arxiv.org/pdf/2103.09058)
- [cs.CY](https://arxiv.org/list/cs.CY/recent) | [cs.HC](https://arxiv.org/list/cs.HC/recent)

A diverse representation of different demographic groups in AI training data sets is important in ensuring that the models will work for a large range of users. To this end, recent efforts in AI fairness and inclusion have advocated for creating AI data sets that are well-balanced across race, gender, socioeconomic status, and disability status. In this paper, we contribute to this line of work by focusing on the representation of age by asking whether older adults are represented proportionally to the population at large in AI data sets. We examine publicly-available information about 92 face data sets to understand how they codify age as a case study to investigate how the subjects' ages are recorded and whether older generations are represented. We find that older adults are very under-represented; five data sets in the study that explicitly documented the closed age intervals of their subjects included older adults (defined as older than 65 years), while only one included oldest-old adults (defined as older than 85 years). Additionally, we find that only 24 of the data sets include any age-related information in their documentation or metadata, and that there is no consistent method followed across these data sets to collect and record the subjects' ages. We recognize the unique difficulties in creating representative data sets in terms of age, but raise it as an important dimension that researchers and engineers interested in inclusive AI should consider.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Posted a new arXiv pre-print &quot;Understanding the Representation and Representativeness of Age in <a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw">#AI</a> Data Sets&quot; w/ <a href="https://twitter.com/joon_s_pk?ref_src=twsrc%5Etfw">@joon_s_pk</a> <a href="https://twitter.com/msbernst?ref_src=twsrc%5Etfw">@msbernst</a> <a href="https://twitter.com/_rnbrewer?ref_src=twsrc%5Etfw">@_rnbrewer</a> <a href="https://twitter.com/ecekamar?ref_src=twsrc%5Etfw">@ecekamar</a> - <a href="https://t.co/EQLDDLTmKX">https://t.co/EQLDDLTmKX</a></p>&mdash; Meredith Ringel Morris (@merrierm) <a href="https://twitter.com/merrierm/status/1372203288376926208?ref_src=twsrc%5Etfw">March 17, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 10. Flow-based Self-supervised Density Estimation for Anomalous Sound  Detection

Kota Dohi, Takashi Endo, Harsh Purohit, Ryo Tanabe, Yohei Kawaguchi

- retweets: 62, favorites: 19 (03/18/2021 09:55:41)

- links: [abs](https://arxiv.org/abs/2103.08801) | [pdf](https://arxiv.org/pdf/2103.08801)
- [eess.AS](https://arxiv.org/list/eess.AS/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.SD](https://arxiv.org/list/cs.SD/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

To develop a machine sound monitoring system, a method for detecting anomalous sound is proposed. Exact likelihood estimation using Normalizing Flows is a promising technique for unsupervised anomaly detection, but it can fail at out-of-distribution detection since the likelihood is affected by the smoothness of the data. To improve the detection performance, we train the model to assign higher likelihood to target machine sounds and lower likelihood to sounds from other machines of the same machine type. We demonstrate that this enables the model to incorporate a self-supervised classification-based approach. Experiments conducted using the DCASE 2020 Challenge Task2 dataset showed that the proposed method improves the AUC by 4.6% on average when using Masked Autoregressive Flow (MAF) and by 5.8% when using Glow, which is a significant improvement over the previous method.



