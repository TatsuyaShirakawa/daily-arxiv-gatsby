---
title: Hot Papers 2021-07-08
date: 2021-07-09T07:32:52.Z
template: "post"
draft: false
slug: "hot-papers-2021-07-08"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2021-07-08"
socialImage: "/media/flying-marine.jpg"

---

# 1. Evaluating Large Language Models Trained on Code

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harri Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, Will Guss, Alex Nichol, Igor Babuschkin, Suchir Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech Zaremba

- retweets: 3765, favorites: 109 (07/09/2021 07:32:52)

- links: [abs](https://arxiv.org/abs/2107.03374) | [pdf](https://arxiv.org/pdf/2107.03374)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)

We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Codex paper is out! I&#39;m grateful to have led the Safety and PL workstreams for Codex/Copilot, working along Policy <a href="https://twitter.com/OpenAI?ref_src=twsrc%5Etfw">@OpenAI</a>. There&#39;s many questions about limitations and implications (BI section), a thread on some of our findings:<a href="https://t.co/kf8ig8szIQ">https://t.co/kf8ig8szIQ</a></p>&mdash; Dr Heidy Khlaaf (ŸáÿßŸäÿØŸä ÿÆŸÑÿßŸÅ) (@HeidyKhlaaf) <a href="https://twitter.com/HeidyKhlaaf/status/1412935240742359041?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Excited to finally share a paper on what a huge chunk of OpenAI has been working on lately: building a series of code generation models and assessing their capabilities and societal implications. üßµ <a href="https://t.co/wed7Jj95Nl">https://t.co/wed7Jj95Nl</a></p>&mdash; Miles Brundage (@Miles_Brundage) <a href="https://twitter.com/Miles_Brundage/status/1412934612737613827?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. A Survey on Data Augmentation for Text Classification

Markus Bayer, Marc-Andr√© Kaufhold, Christian Reuter

- retweets: 1677, favorites: 201 (07/09/2021 07:32:53)

- links: [abs](https://arxiv.org/abs/2107.03158) | [pdf](https://arxiv.org/pdf/2107.03158)
- [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)

Data augmentation, the artificial creation of training data for machine learning by transformations, is a widely studied research field across machine learning disciplines. While it is useful for increasing the generalization capabilities of a model, it can also address many other challenges and problems, from overcoming a limited amount of training data over regularizing the objective to limiting the amount data used to protect privacy. Based on a precise description of the goals and applications of data augmentation (C1) and a taxonomy for existing works (C2), this survey is concerned with data augmentation methods for textual classification and aims to achieve a concise and comprehensive overview for researchers and practitioners (C3). Derived from the taxonomy, we divided more than 100 methods into 12 different groupings and provide state-of-the-art references expounding which methods are highly promising (C4). Finally, research perspectives that may constitute a building block for future work are given (C5).

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Two great NLP survey papers this week:<br><br>1) Survey on Data Augmentation for Text Classification - <a href="https://t.co/do1nwCWLTc">https://t.co/do1nwCWLTc</a><br><br>2) Survey on Dialogue Summarization: Advances and New Frontiers - <a href="https://t.co/91EXH3Jpxp">https://t.co/91EXH3Jpxp</a> <a href="https://t.co/N1xvKMI6oz">pic.twitter.com/N1xvKMI6oz</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1413094930441031680?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. A Survey on Dialogue Summarization: Recent Advances and New Frontiers

Xiachong Feng, Xiaocheng Feng, Bing Qin

- retweets: 1677, favorites: 201 (07/09/2021 07:32:53)

- links: [abs](https://arxiv.org/abs/2107.03175) | [pdf](https://arxiv.org/pdf/2107.03175)
- [cs.CL](https://arxiv.org/list/cs.CL/recent)

With the development of dialogue systems and natural language generation techniques, the resurgence of dialogue summarization has attracted significant research attentions, which aims to condense the original dialogue into a shorter version covering salient information. However, there remains a lack of comprehensive survey for this task. To this end, we take the first step and present a thorough review of this research field. In detail, we provide an overview of publicly available research datasets, summarize existing works according to the domain of input dialogue as well as organize leaderboards under unified metrics. Furthermore, we discuss some future directions and give our thoughts. We hope that this first survey of dialogue summarization can provide the community with a quick access and a general picture to this task and motivate future researches.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Two great NLP survey papers this week:<br><br>1) Survey on Data Augmentation for Text Classification - <a href="https://t.co/do1nwCWLTc">https://t.co/do1nwCWLTc</a><br><br>2) Survey on Dialogue Summarization: Advances and New Frontiers - <a href="https://t.co/91EXH3Jpxp">https://t.co/91EXH3Jpxp</a> <a href="https://t.co/N1xvKMI6oz">pic.twitter.com/N1xvKMI6oz</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1413094930441031680?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. SoundStream: An End-to-End Neural Audio Codec

Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, Marco Tagliasacchi

- retweets: 200, favorites: 94 (07/09/2021 07:32:53)

- links: [abs](https://arxiv.org/abs/2107.03312) | [pdf](https://arxiv.org/pdf/2107.03312)
- [cs.SD](https://arxiv.org/list/cs.SD/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [eess.AS](https://arxiv.org/list/eess.AS/recent)

We present SoundStream, a novel neural audio codec that can efficiently compress speech, music and general audio at bitrates normally targeted by speech-tailored codecs. SoundStream relies on a model architecture composed by a fully convolutional encoder/decoder network and a residual vector quantizer, which are trained jointly end-to-end. Training leverages recent advances in text-to-speech and speech enhancement, which combine adversarial and reconstruction losses to allow the generation of high-quality audio content from quantized embeddings. By training with structured dropout applied to quantizer layers, a single model can operate across variable bitrates from 3kbps to 18kbps, with a negligible quality loss when compared with models trained at fixed bitrates. In addition, the model is amenable to a low latency implementation, which supports streamable inference and runs in real time on a smartphone CPU. In subjective evaluations using audio at 24kHz sampling rate, SoundStream at 3kbps outperforms Opus at 12kbps and approaches EVS at 9.6kbps. Moreover, we are able to perform joint compression and enhancement either at the encoder or at the decoder side with no additional latency, which we demonstrate through background noise suppression for speech.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Check Soundstream, our neural audio codec:<br>* outperforms Opus &amp; EVS on speech &amp; music w/ up to 4x fewer bits<br>* scalable: 1 model for all bitrates<br>* runs real-time on 1 smartphone CPU<br>* controllable denoising<br>Paper: <a href="https://t.co/Lwap8acnYz">https://t.co/Lwap8acnYz</a><br>Samples üîä : <a href="https://t.co/32HqtCMDpI">https://t.co/32HqtCMDpI</a><br>1/5 <a href="https://t.co/QjgmBWJTI2">pic.twitter.com/QjgmBWJTI2</a></p>&mdash; Neil Zeghidour (@neilzegh) <a href="https://twitter.com/neilzegh/status/1413063896294961159?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">SoundStream: An End-to-End Neural Audio Codec<br>pdf: <a href="https://t.co/UyRE6snXGW">https://t.co/UyRE6snXGW</a><br>abs: <a href="https://t.co/nWjWyQ3pTk">https://t.co/nWjWyQ3pTk</a><br>neural audio codec that can efficiently compress speech, music and general audio at bitrates normally targeted by speech-tailored codecs <a href="https://t.co/29GTuTyQ28">pic.twitter.com/29GTuTyQ28</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1412941813158141956?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. GLiT: Neural Architecture Search for Global and Local Image Transformer

Boyu Chen, Peixia Li, Chuming Li, Baopu Li, Lei Bai, Chen Lin, Ming Sun, Junjie yan, Wanli Ouyang

- retweets: 143, favorites: 44 (07/09/2021 07:32:53)

- links: [abs](https://arxiv.org/abs/2107.02960) | [pdf](https://arxiv.org/pdf/2107.02960)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)

We introduce the first Neural Architecture Search (NAS) method to find a better transformer architecture for image recognition. Recently, transformers without CNN-based backbones are found to achieve impressive performance for image recognition. However, the transformer is designed for NLP tasks and thus could be sub-optimal when directly used for image recognition. In order to improve the visual representation ability for transformers, we propose a new search space and searching algorithm. Specifically, we introduce a locality module that models the local correlations in images explicitly with fewer computational cost. With the locality module, our search space is defined to let the search algorithm freely trade off between global and local information as well as optimizing the low-level design choice in each module. To tackle the problem caused by huge search space, a hierarchical neural architecture search method is proposed to search the optimal vision transformer from two levels separately with the evolutionary algorithm. Extensive experiments on the ImageNet dataset demonstrate that our method can find more discriminative and efficient transformer variants than the ResNet family (e.g., ResNet101) and the baseline ViT for image classification.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">GLiT: Neural Architecture Search for Global and Local Image Transformer<br>pdf: <a href="https://t.co/9EVQvoLvyX">https://t.co/9EVQvoLvyX</a><br>method can find more discriminative and efficient transformer variants than the ResNet family (e.g., ResNet101) and the baseline ViT for image classification <a href="https://t.co/fkFVfMdHfq">pic.twitter.com/fkFVfMdHfq</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1412937626647252999?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. Deep Extrapolation for Attribute-Enhanced Generation

Alvin Chan, Ali Madani, Ben Krause, Nikhil Naik

- retweets: 108, favorites: 78 (07/09/2021 07:32:53)

- links: [abs](https://arxiv.org/abs/2107.02968) | [pdf](https://arxiv.org/pdf/2107.02968)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent) | [q-bio.QM](https://arxiv.org/list/q-bio.QM/recent)

Attribute extrapolation in sample generation is challenging for deep neural networks operating beyond the training distribution. We formulate a new task for extrapolation in sequence generation, focusing on natural language and proteins, and propose GENhance, a generative framework that enhances attributes through a learned latent space. Trained on movie reviews and a computed protein stability dataset, GENhance can generate strongly-positive text reviews and highly stable protein sequences without being exposed to similar data during training. We release our benchmark tasks and models to contribute to the study of generative modeling extrapolation and data-driven design in biology and chemistry.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Can generative AI learn to extrapolate? We explore how to generate sequences that enhance desired attributes-- beyond what was seen in training. Works pretty well in <a href="https://twitter.com/hashtag/NLP?src=hash&amp;ref_src=twsrc%5Etfw">#NLP</a> and <a href="https://twitter.com/hashtag/proteins?src=hash&amp;ref_src=twsrc%5Etfw">#proteins</a>!<br><br>Blog: <a href="https://t.co/dUAgZuX0W5">https://t.co/dUAgZuX0W5</a><br>Paper: <a href="https://t.co/kY4TruHUTu">https://t.co/kY4TruHUTu</a><br>Code: <a href="https://t.co/jFNccTxW0M">https://t.co/jFNccTxW0M</a> <a href="https://t.co/1v55MlMr3m">pic.twitter.com/1v55MlMr3m</a></p>&mdash; Ali Madani (@thisismadani) <a href="https://twitter.com/thisismadani/status/1413142806541922316?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. Structured Denoising Diffusion Models in Discrete State-Spaces

Jacob Austin, Daniel Johnson, Jonathan Ho, Danny Tarlow, Rianne van den Berg

- retweets: 111, favorites: 63 (07/09/2021 07:32:54)

- links: [abs](https://arxiv.org/abs/2107.03006) | [pdf](https://arxiv.org/pdf/2107.03006)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.CV](https://arxiv.org/list/cs.CV/recent)

Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown impressive results on image and waveform generation in continuous state spaces. Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs), diffusion-like generative models for discrete data that generalize the multinomial diffusion model of Hoogeboom et al. 2021, by going beyond corruption processes with uniform transition probabilities. This includes corruption with transition matrices that mimic Gaussian kernels in continuous space, matrices based on nearest neighbors in embedding space, and matrices that introduce absorbing states. The third allows us to draw a connection between diffusion models and autoregressive and mask-based generative models. We show that the choice of transition matrix is an important design decision that leads to improved results in image and text domains. We also introduce a new loss function that combines the variational lower bound with an auxiliary cross entropy loss. For text, this model class achieves strong results on character-level text generation while scaling to large vocabularies on LM1B. On the image dataset CIFAR-10, our models approach the sample quality and exceed the log-likelihood of the continuous-space DDPM model.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Structured Denoising Diffusion Models in Discrete<br>State-Spaces<br>pdf: <a href="https://t.co/OAc8ffsJCD">https://t.co/OAc8ffsJCD</a><br>abs: <a href="https://t.co/mQHJTkXHqA">https://t.co/mQHJTkXHqA</a><br>D3PMs, a class of models that improves diffusion models for discrete data by defining new kinds of discrete corruption processes <a href="https://t.co/aYCovG2vyn">pic.twitter.com/aYCovG2vyn</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1412935479180279810?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 8. Big Data Information and Nowcasting: Consumption and Investment from  Bank Transactions in Turkey

Ali B. Barlas, Seda Guler Mert, Berk Orkun Isa, Alvaro Ortiz, Tomasa Rodrigo, Baris Soybilgen, Ege Yazgan

- retweets: 90, favorites: 68 (07/09/2021 07:32:54)

- links: [abs](https://arxiv.org/abs/2107.03299) | [pdf](https://arxiv.org/pdf/2107.03299)
- [econ.EM](https://arxiv.org/list/econ.EM/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [q-fin.ST](https://arxiv.org/list/q-fin.ST/recent)

We use the aggregate information from individual-to-firm and firm-to-firm in Garanti BBVA Bank transactions to mimic domestic private demand. Particularly, we replicate the quarterly national accounts aggregate consumption and investment (gross fixed capital formation) and its bigger components (Machinery and Equipment and Construction) in real time for the case of Turkey. In order to validate the usefulness of the information derived from these indicators we test the nowcasting ability of both indicators to nowcast the Turkish GDP using different nowcasting models. The results are successful and confirm the usefulness of Consumption and Investment Banking transactions for nowcasting purposes. The value of the Big data information is more relevant at the beginning of the nowcasting process, when the traditional hard data information is scarce. This makes this information specially relevant for those countries where statistical release lags are longer like the Emerging Markets.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Now you can check how we measure Turkish consumption and investment  in real time and how we can introduce these data in traditional Nowcasting models ‚û°Ô∏è <a href="https://t.co/nxibEvcNFf">https://t.co/nxibEvcNFf</a> <a href="https://twitter.com/ali_hakan_kara?ref_src=twsrc%5Etfw">@ali_hakan_kara</a> <a href="https://twitter.com/JuriMarcucci?ref_src=twsrc%5Etfw">@JuriMarcucci</a> <a href="https://twitter.com/RefetGurkaynak?ref_src=twsrc%5Etfw">@RefetGurkaynak</a> <a href="https://twitter.com/SimdiTahmin?ref_src=twsrc%5Etfw">@SimdiTahmin</a> <a href="https://t.co/Me7mNr76A5">pic.twitter.com/Me7mNr76A5</a></p>&mdash; Alvaro Ortiz (@alvaroortiz1968) <a href="https://twitter.com/alvaroortiz1968/status/1413045266056458241?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. A Survey of Uncertainty in Deep Neural Networks

Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, Muhammad Shahzad, Wen Yang, Richard Bamler, Xiao Xiang Zhu

- retweets: 100, favorites: 54 (07/09/2021 07:32:54)

- links: [abs](https://arxiv.org/abs/2107.03342) | [pdf](https://arxiv.org/pdf/2107.03342)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

Due to their increasing spread, confidence in neural network predictions became more and more important. However, basic neural networks do not deliver certainty estimates or suffer from over or under confidence. Many researchers have been working on understanding and quantifying uncertainty in a neural network's prediction. As a result, different types and sources of uncertainty have been identified and a variety of approaches to measure and quantify uncertainty in neural networks have been proposed. This work gives a comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. It is intended to give anyone interested in uncertainty estimation in neural networks a broad overview and introduction, without presupposing prior knowledge in this field. A comprehensive introduction to the most crucial sources of uncertainty is given and their separation into reducible model uncertainty and not reducible data uncertainty is presented. The modeling of these uncertainties based on deterministic neural networks, Bayesian neural networks, ensemble of neural networks, and test-time data augmentation approaches is introduced and different branches of these fields as well as the latest developments are discussed. For a practical application, we discuss different measures of uncertainty, approaches for the calibration of neural networks and give an overview of existing baselines and implementations. Different examples from the wide spectrum of challenges in different fields give an idea of the needs and challenges regarding uncertainties in practical applications. Additionally, the practical limitations of current methods for mission- and safety-critical real world applications are discussed and an outlook on the next steps towards a broader usage of such methods is given.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A Survey of Uncertainty in Deep Neural Networks. (arXiv:2107.03342v1 [cs.LG]) <a href="https://t.co/lgAV7jJ6rU">https://t.co/lgAV7jJ6rU</a></p>&mdash; Stat.ML Papers (@StatMLPapers) <a href="https://twitter.com/StatMLPapers/status/1413041989621256197?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 10. The Geography of Open Source Software: Evidence from GitHub

Johannes Wachs, Mariusz Nitecki, William Schueller, Axel Polleres

- retweets: 79, favorites: 39 (07/09/2021 07:32:54)

- links: [abs](https://arxiv.org/abs/2107.03200) | [pdf](https://arxiv.org/pdf/2107.03200)
- [cs.SI](https://arxiv.org/list/cs.SI/recent) | [cs.CY](https://arxiv.org/list/cs.CY/recent)

Open Source Software plays an important role in the digital economy. Yet although software production is amenable to remote collaboration and its end products are easily shared across distances, software development seems to cluster geographically in places such as Silicon Valley, London, or Berlin. And while recent work indicates that positive effects of open source software production accrue locally through knowledge spillovers and information effects, up-to-date data on the geographic distribution of active open source developers remains limited. Here we analyze the geographic distribution of more than half a million active contributors to GitHub located in early 2021 at various spatial scales. Comparing our data with results from before 2010, we find a significant increase in the relative share of developers based in Asia, Latin America and Eastern Europe, suggesting a more even spread of OSS developers globally. Within countries, however, we find significant concentration in regions, exceeding by some margin the concentration of workers in high-tech fields. We relate OSS activity to a number of social and technological indicators at both scales using a multiple regression framework. Despite the potential of OSS as a distributed mode of collaborative work, the data suggest that OSS activity remains highly localized.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We have a new preprint (<a href="https://t.co/CO54jx53yX">https://t.co/CO54jx53yX</a>, /w Mariusz Nitecki, <a href="https://twitter.com/wschuell1?ref_src=twsrc%5Etfw">@wschuell1</a>, <a href="https://twitter.com/AxelPolleres?ref_src=twsrc%5Etfw">@AxelPolleres</a>) on the geography of open source software devs. We geolocated and counted active devs on GitHub in countries and regions, comparing vs 10+ yrs ago. Get the data: <a href="https://t.co/NhVDxkYuGa">https://t.co/NhVDxkYuGa</a> <a href="https://t.co/2c2PQTwyoQ">pic.twitter.com/2c2PQTwyoQ</a></p>&mdash; Johannes Wachs (@johannes_wachs) <a href="https://twitter.com/johannes_wachs/status/1413075641554063367?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 11. Learning Latent Actions to Control Assistive Robots

Dylan P. Losey, Hong Jun Jeon, Mengxi Li, Krishnan Srinivasan, Ajay Mandlekar, Animesh Garg, Jeannette Bohg, Dorsa Sadigh

- retweets: 30, favorites: 27 (07/09/2021 07:32:54)

- links: [abs](https://arxiv.org/abs/2107.02907) | [pdf](https://arxiv.org/pdf/2107.02907)
- [cs.RO](https://arxiv.org/list/cs.RO/recent)

Assistive robot arms enable people with disabilities to conduct everyday tasks on their own. These arms are dexterous and high-dimensional; however, the interfaces people must use to control their robots are low-dimensional. Consider teleoperating a 7-DoF robot arm with a 2-DoF joystick. The robot is helping you eat dinner, and currently you want to cut a piece of tofu. Today's robots assume a pre-defined mapping between joystick inputs and robot actions: in one mode the joystick controls the robot's motion in the x-y plane, in another mode the joystick controls the robot's z-yaw motion, and so on. But this mapping misses out on the task you are trying to perform! Ideally, one joystick axis should control how the robot stabs the tofu and the other axis should control different cutting motions. Our insight is that we can achieve intuitive, user-friendly control of assistive robots by embedding the robot's high-dimensional actions into low-dimensional and human-controllable latent actions. We divide this process into three parts. First, we explore models for learning latent actions from offline task demonstrations, and formalize the properties that latent actions should satisfy. Next, we combine learned latent actions with autonomous robot assistance to help the user reach and maintain their high-level goals. Finally, we learn a personalized alignment model between joystick inputs and latent actions. We evaluate our resulting approach in four user studies where non-disabled participants reach marshmallows, cook apple pie, cut tofu, and assemble dessert. We then test our approach with two disabled adults who leverage assistive devices on a daily basis.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Making assistive teleoperation intuitive, easy to operate, and precise! The journal version of our work on the framework of learned latent actions + shared autonomy + personalization is out.  We also have new studies with users with disability.<br>Paper: <a href="https://t.co/KXomKMMhvV">https://t.co/KXomKMMhvV</a> <a href="https://t.co/knWAxPOx4Z">pic.twitter.com/knWAxPOx4Z</a></p>&mdash; Dorsa Sadigh (@DorsaSadigh) <a href="https://twitter.com/DorsaSadigh/status/1413200452993261573?ref_src=twsrc%5Etfw">July 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



