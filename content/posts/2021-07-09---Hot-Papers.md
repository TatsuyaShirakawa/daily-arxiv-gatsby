---
title: Hot Papers 2021-07-09
date: 2021-07-12T09:10:21.Z
template: "post"
draft: false
slug: "hot-papers-2021-07-09"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2021-07-09"
socialImage: "/media/flying-marine.jpg"

---

# 1. BumbleBee: A Transformer for Music

Lucas Fenaux, Maria Juliana Quintero

- retweets: 1181, favorites: 228 (07/12/2021 09:10:21)

- links: [abs](https://arxiv.org/abs/2107.03443) | [pdf](https://arxiv.org/pdf/2107.03443)
- [cs.SD](https://arxiv.org/list/cs.SD/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [eess.AS](https://arxiv.org/list/eess.AS/recent)

We will introduce BumbleBee, a transformer model that will generate MIDI music data . We will tackle the issue of transformers applied to long sequences by implementing a longformer generative model that uses dilating sliding windows to compute the attention layers. We will compare our results to that of the music transformer and Long-Short term memory (LSTM) to benchmark our results. This analysis will be performed using piano MIDI files, in particular , the JSB Chorales dataset that has already been used for other research works (Huang et al., 2018)

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">BumbleBee: A Transformer for Music<br>pdf: <a href="https://t.co/hB2na4ONI6">https://t.co/hB2na4ONI6</a><br>abs: <a href="https://t.co/KftvnRfM2Z">https://t.co/KftvnRfM2Z</a> <a href="https://t.co/Ytqf7ouSE2">pic.twitter.com/Ytqf7ouSE2</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1413298285352296448?ref_src=twsrc%5Etfw">July 9, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. Anticipating Safety Issues in E2E Conversational AI: Framework and  Tooling

Emily Dinan, Gavin Abercrombie, A. Stevie Bergman, Shannon Spruit, Dirk Hovy, Y-Lan Boureau, Verena Rieser

- retweets: 343, favorites: 55 (07/12/2021 09:10:21)

- links: [abs](https://arxiv.org/abs/2107.03451) | [pdf](https://arxiv.org/pdf/2107.03451)
- [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)

Over the last several years, end-to-end neural conversational agents have vastly improved in their ability to carry a chit-chat conversation with humans. However, these models are often trained on large datasets from the internet, and as a result, may learn undesirable behaviors from this data, such as toxic or otherwise harmful language. Researchers must thus wrestle with the issue of how and when to release these models. In this paper, we survey the problem landscape for safety for end-to-end conversational AI and discuss recent and related work. We highlight tensions between values, potential positive impact and potential harms, and provide a framework for making decisions about whether and how to release these models, following the tenets of value-sensitive design. We additionally provide a suite of tools to enable researchers to make better-informed decisions about training and releasing end-to-end conversational AI models.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Proud and excited to release: <br>&quot;Anticipating Safety Issues in E2E <a href="https://twitter.com/hashtag/ConvAI?src=hash&amp;ref_src=twsrc%5Etfw">#ConvAI</a>: Framework and Tooling&quot; <br><br>with <a href="https://twitter.com/em_dinan?ref_src=twsrc%5Etfw">@em_dinan</a> <a href="https://twitter.com/gavin_does_nlp?ref_src=twsrc%5Etfw">@gavin_does_nlp</a> <br>Stevie Bergman <br>Shannon Spruit <a href="https://twitter.com/dirk_hovy?ref_src=twsrc%5Etfw">@dirk_hovy</a> <a href="https://twitter.com/yboureau?ref_src=twsrc%5Etfw">@yboureau</a> <a href="https://twitter.com/facebookai?ref_src=twsrc%5Etfw">@facebookai</a><a href="https://twitter.com/HeriotWattUni?ref_src=twsrc%5Etfw">@HeriotWattUni</a><br>Populytics<a href="https://twitter.com/MilaNLProc?ref_src=twsrc%5Etfw">@MilaNLProc</a><a href="https://twitter.com/helloalana?ref_src=twsrc%5Etfw">@helloalana</a><a href="https://t.co/YOVZr4baa5">https://t.co/YOVZr4baa5</a></p>&mdash; Verena Rieser (@verena_rieser) <a href="https://twitter.com/verena_rieser/status/1413419825976709121?ref_src=twsrc%5Etfw">July 9, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. Information-theoretic characterization of the complete  genotype-phenotype map of a complex pre-biotic world

Nitash C G, Christoph Adami

- retweets: 112, favorites: 50 (07/12/2021 09:10:21)

- links: [abs](https://arxiv.org/abs/2107.03522) | [pdf](https://arxiv.org/pdf/2107.03522)
- [cs.IT](https://arxiv.org/list/cs.IT/recent) | [q-bio.MN](https://arxiv.org/list/q-bio.MN/recent) | [q-bio.PE](https://arxiv.org/list/q-bio.PE/recent)

How information is encoded in bio-molecular sequences is difficult to quantify since such an analysis usually requires sampling an exponentially large genetic space. Here we show how information theory reveals both robust and compressed encodings in the largest complete genotype-phenotype map (over 5 trillion sequences) obtained to date.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We analyzed over 5.4 trillion sequences of potential self-replicators in a digital world to measure how much information it takes to replicate in this world, and how that information is encoded in the sequence. <a href="https://t.co/oHrglbdMjv">https://t.co/oHrglbdMjv</a></p>&mdash; Chris Adami (@ChristophAdami) <a href="https://twitter.com/ChristophAdami/status/1413302329416241152?ref_src=twsrc%5Etfw">July 9, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. Learning Vision-Guided Quadrupedal Locomotion End-to-End with  Cross-Modal Transformers

Ruihan Yang, Minghao Zhang, Nicklas Hansen, Huazhe Xu, Xiaolong Wang

- retweets: 110, favorites: 37 (07/12/2021 09:10:21)

- links: [abs](https://arxiv.org/abs/2107.03996) | [pdf](https://arxiv.org/pdf/2107.03996)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.RO](https://arxiv.org/list/cs.RO/recent)

We propose to address quadrupedal locomotion tasks using Reinforcement Learning (RL) with a Transformer-based model that learns to combine proprioceptive information and high-dimensional depth sensor inputs. While learning-based locomotion has made great advances using RL, most methods still rely on domain randomization for training blind agents that generalize to challenging terrains. Our key insight is that proprioceptive states only offer contact measurements for immediate reaction, whereas an agent equipped with visual sensory observations can learn to proactively maneuver environments with obstacles and uneven terrain by anticipating changes in the environment many steps ahead. In this paper, we introduce LocoTransformer, an end-to-end RL method for quadrupedal locomotion that leverages a Transformer-based model for fusing proprioceptive states and visual observations. We evaluate our method in challenging simulated environments with different obstacles and uneven terrain. We show that our method obtains significant improvements over policies with only proprioceptive state inputs, and that Transformer-based models further improve generalization across environments. Our project page with videos is at https://RchalYang.github.io/LocoTransformer .

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers<br>pdf: <a href="https://t.co/s8rWEVi1D5">https://t.co/s8rWEVi1D5</a><br>abs: <a href="https://t.co/nO9Po6NdUW">https://t.co/nO9Po6NdUW</a><br>project page: <a href="https://t.co/DTX3TqDBKa">https://t.co/DTX3TqDBKa</a> <a href="https://t.co/tGpsmBivPm">pic.twitter.com/tGpsmBivPm</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1413297611235381252?ref_src=twsrc%5Etfw">July 9, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. Quantifying the rise and fall of scientific fields

Chakresh Singh, Emma Barme, Robert Ward, Liubov Tupikina, Marc Santolini

- retweets: 92, favorites: 34 (07/12/2021 09:10:21)

- links: [abs](https://arxiv.org/abs/2107.03749) | [pdf](https://arxiv.org/pdf/2107.03749)
- [physics.soc-ph](https://arxiv.org/list/physics.soc-ph/recent) | [cs.SI](https://arxiv.org/list/cs.SI/recent)

Science advances by pushing the boundaries of the adjacent possible. While the global scientific enterprise grows at an exponential pace, at the mesoscopic level the exploration and exploitation of research ideas is reflected through the rise and fall of research fields. The empirical literature has largely studied such dynamics on a case-by-case basis, with a focus on explaining how and why communities of knowledge production evolve. Although fields rise and fall on different temporal and population scales, they are generally argued to pass through a common set of evolutionary stages.To understand the social processes that drive these stages beyond case studies, we need a way to quantify and compare different fields on the same terms. In this paper we develop techniques for identifying scale-invariant patterns in the evolution of scientific fields, and demonstrate their usefulness using 1.5 million preprints from the arXiv repository covering $175$ research fields spanning Physics, Mathematics, Computer Science, Quantitative Biology and Quantitative Finance. We show that fields consistently follows a rise and fall pattern captured by a two parameters right-tailed Gumbel temporal distribution. We introduce a field-specific rescaled time and explore the generic properties shared by articles and authors at the creation, adoption, peak, and decay evolutionary phases. We find that the early phase of a field is characterized by the mixing of cognitively distant fields by small teams of interdisciplinary authors, while late phases exhibit the role of specialized, large teams building on the previous works in the field. This method provides foundations to quantitatively explore the generic patterns underlying the evolution of research fields in science, with general implications in innovation studies.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Quantifying the rise and fall of scientific fields. (arXiv:2107.03749v1 [physics.soc-ph]) <a href="https://t.co/lU6EtBxCBY">https://t.co/lU6EtBxCBY</a></p>&mdash; NetScience (@net_science) <a href="https://twitter.com/net_science/status/1413392088188731392?ref_src=twsrc%5Etfw">July 9, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with  100M FLOPs

Yikang Zhang, Zhuo Chen, Zhao Zhong

- retweets: 64, favorites: 34 (07/12/2021 09:10:22)

- links: [abs](https://arxiv.org/abs/2107.03815) | [pdf](https://arxiv.org/pdf/2107.03815)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

In this paper, we propose a Collaboration of Experts (CoE) framework to pool together the expertise of multiple networks towards a common aim. Each expert is an individual network with expertise on a unique portion of the dataset, which enhances the collective capacity. Given a sample, an expert is selected by the delegator, which simultaneously outputs a rough prediction to support early termination. To fulfill this framework, we propose three modules to impel each model to play its role, namely weight generation module (WGM), label generation module (LGM) and variance calculation module (VCM). Our method achieves the state-of-the-art performance on ImageNet, 80.7% top-1 accuracy with 194M FLOPs. Combined with PWLU activation function and CondConv, CoE further achieves the accuracy of 80.0% with only 100M FLOPs for the first time. More importantly, our method is hardware friendly and achieves a 3-6x speedup compared with some existing conditional computation approaches.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs<br>pdf: <a href="https://t.co/z7FLsUDC2M">https://t.co/z7FLsUDC2M</a><br>abs: <a href="https://t.co/qYUHbEkZIH">https://t.co/qYUHbEkZIH</a><br>Combined with PWLU activation function and CondConv, CoE further achieves the accuracy of 80.0% with only 100M FLOPs <a href="https://t.co/3VCGY0JZCg">pic.twitter.com/3VCGY0JZCg</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1413307116547420167?ref_src=twsrc%5Etfw">July 9, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. Offline Meta-Reinforcement Learning with Online Self-Supervision

Vitchyr H. Pong, Ashvin Nair, Laura Smith, Catherine Huang, Sergey Levine

- retweets: 56, favorites: 16 (07/12/2021 09:10:22)

- links: [abs](https://arxiv.org/abs/2107.03974) | [pdf](https://arxiv.org/pdf/2107.03974)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.RO](https://arxiv.org/list/cs.RO/recent)

Meta-reinforcement learning (RL) can be used to train policies that quickly adapt to new tasks with orders of magnitude less data than standard RL, but this fast adaptation often comes at the cost of greatly increasing the amount of reward supervision during meta-training time. Offline meta-RL removes the need to continuously provide reward supervision because rewards must only be provided once when the offline dataset is generated. In addition to the challenges of offline RL, a unique distribution shift is present in meta RL: agents learn exploration strategies that can gather the experience needed to learn a new task, and also learn adaptation strategies that work well when presented with the trajectories in the dataset, but the adaptation strategies are not adapted to the data distribution that the learned exploration strategies collect. Unlike the online setting, the adaptation and exploration strategies cannot effectively adapt to each other, resulting in poor performance. In this paper, we propose a hybrid offline meta-RL algorithm, which uses offline data with rewards to meta-train an adaptive policy, and then collects additional unsupervised online data, without any ground truth reward labels, to bridge this distribution shift problem. Our method uses the offline data to learn the distribution of reward functions, which is then sampled to self-supervise reward labels for the additional online data. By removing the need to provide reward labels for the online experience, our approach can be more practical to use in settings where reward supervision would otherwise be provided manually. We compare our method to prior work on offline meta-RL on simulated robot locomotion and manipulation tasks and find that using additional data and self-generated rewards significantly improves an agent's ability to generalize.




# 8. Imitation by Predicting Observations

Andrew Jaegle, Yury Sulsky, Arun Ahuja, Jake Bruce, Rob Fergus, Greg Wayne

- retweets: 19, favorites: 48 (07/12/2021 09:10:22)

- links: [abs](https://arxiv.org/abs/2107.03851) | [pdf](https://arxiv.org/pdf/2107.03851)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)

Imitation learning enables agents to reuse and adapt the hard-won expertise of others, offering a solution to several key challenges in learning behavior. Although it is easy to observe behavior in the real-world, the underlying actions may not be accessible. We present a new method for imitation solely from observations that achieves comparable performance to experts on challenging continuous control tasks while also exhibiting robustness in the presence of observations unrelated to the task. Our method, which we call FORM (for "Future Observation Reward Model") is derived from an inverse RL objective and imitates using a model of expert behavior learned by generative modelling of the expert's observations, without needing ground truth actions. We show that FORM performs comparably to a strong baseline IRL method (GAIL) on the DeepMind Control Suite benchmark, while outperforming GAIL in the presence of task-irrelevant features.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Imitation by Predicting Observations<br>pdf: <a href="https://t.co/3FSIIEKDeZ">https://t.co/3FSIIEKDeZ</a><br>abs: <a href="https://t.co/6FQR1sBnHk">https://t.co/6FQR1sBnHk</a><br><br>derived from an inverse RL objective and imitates using a model of expert behavior learned by generative modelling of the expert’s observations, without needing ground truth actions <a href="https://t.co/NgWCLcWoFe">pic.twitter.com/NgWCLcWoFe</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1413302887900385284?ref_src=twsrc%5Etfw">July 9, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. Likelihood-Free Frequentist Inference: Bridging Classical Statistics and  Machine Learning in Simulation and Uncertainty Quantification

Niccolò Dalmasso, David Zhao, Rafael Izbicki, Ann B. Lee

- retweets: 36, favorites: 26 (07/12/2021 09:10:22)

- links: [abs](https://arxiv.org/abs/2107.03920) | [pdf](https://arxiv.org/pdf/2107.03920)
- [stat.ML](https://arxiv.org/list/stat.ML/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

Many areas of science make extensive use of computer simulators that implicitly encode likelihood functions for complex systems. Classical statistical methods are poorly suited for these so-called likelihood-free inference (LFI) settings, outside the asymptotic and low-dimensional regimes. Although new machine learning methods, such as normalizing flows, have revolutionized the sample efficiency and capacity of LFI methods, it remains an open question whether they produce reliable measures of uncertainty. In this paper, we present a statistical framework for LFI that unifies classical statistics with modern machine learning to: (1) construct frequentist confidence sets and hypothesis tests with finite-sample guarantees of nominal coverage (type I error control) and power, and (2) provide rigorous diagnostics for assessing empirical coverage over the entire parameter space. We refer to our framework as likelihood-free frequentist inference (LF2I). Any method that estimates a test statistic, such as the likelihood ratio, can be plugged into our framework to create powerful tests and confidence sets with correct coverage. In this work, we specifically study two test statistics (ACORE and BFF), which, respectively, maximize versus integrate an odds function over the parameter space. Our theoretical and empirical results offer multifaceted perspectives on error sources and challenges in likelihood-free frequentist inference.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Likelihood-Free Frequentist Inference: Bridging Classical Statistics and Machine Learning in Simulation and Uncertainty Quantification. (arXiv:2107.03920v1 [<a href="https://t.co/zjV5HgYw5a">https://t.co/zjV5HgYw5a</a>]) <a href="https://t.co/6vnU8TnO92">https://t.co/6vnU8TnO92</a></p>&mdash; Stat.ML Papers (@StatMLPapers) <a href="https://twitter.com/StatMLPapers/status/1413404479337205763?ref_src=twsrc%5Etfw">July 9, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



