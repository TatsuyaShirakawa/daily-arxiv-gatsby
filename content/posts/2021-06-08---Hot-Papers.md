---
title: Hot Papers 2021-06-08
date: 2021-06-09T10:51:32.Z
template: "post"
draft: false
slug: "hot-papers-2021-06-08"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2021-06-08"
socialImage: "/media/flying-marine.jpg"

---

# 1. Tabular Data: Deep Learning is Not All You Need

Ravid Shwartz-Ziv, Amitai Armon

- retweets: 9476, favorites: 11 (06/09/2021 10:51:34)

- links: [abs](https://arxiv.org/abs/2106.03253) | [pdf](https://arxiv.org/pdf/2106.03253)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Tabular Data: Deep Learning is Not All You Need. Nice comparison betw XGBoost &amp; recent DNNs for tabular data. Surprise?! XGboost comes out on top for most datasets (esp. those not incl in the DNN papers). What&#39;s even better? An ensemble of XGBoost &amp; DNNs <a href="https://t.co/GOeH3XxqV4">https://t.co/GOeH3XxqV4</a> <a href="https://t.co/kCNAJPggon">pic.twitter.com/kCNAJPggon</a></p>&mdash; Sebastian Raschka (@rasbt) <a href="https://twitter.com/rasbt/status/1402290438803951628?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. The Inductive Bias of Quantum Kernels

Jonas M. K√ºbler, Simon Buchholz, Bernhard Sch√∂lkopf

- retweets: 3654, favorites: 287 (06/09/2021 10:51:35)

- links: [abs](https://arxiv.org/abs/2106.03747) | [pdf](https://arxiv.org/pdf/2106.03747)
- [quant-ph](https://arxiv.org/list/quant-ph/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üßê Can Quantum Machine Learning Models outperform classical ML models?<br><br>We worked on a few steps towards answering this question: <a href="https://t.co/kZiWiywTMM">https://t.co/kZiWiywTMM</a><br>with Simon Buchholz and <a href="https://twitter.com/bschoelkopf?ref_src=twsrc%5Etfw">@bschoelkopf</a> <br><br>a Thread üìú 1/8 <a href="https://t.co/Ch7TE9CxEi">pic.twitter.com/Ch7TE9CxEi</a></p>&mdash; Jonas M. K√ºbler (@jonas_kubler) <a href="https://twitter.com/jonas_kubler/status/1402158135008169985?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. Meta-Learning with Fewer Tasks through Task Interpolation

Huaxiu Yao, Linjun Zhang, Chelsea Finn

- retweets: 841, favorites: 163 (06/09/2021 10:51:36)

- links: [abs](https://arxiv.org/abs/2106.02695) | [pdf](https://arxiv.org/pdf/2106.02695)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Meta-learning methods need a large set of training tasks. We introduce a simple regularizer that helps, especially when you don‚Äôt have a lot of tasks.<br><br>Meta-Learning with Fewer Tasks through Task Interpolation<br>Paper: <a href="https://t.co/4xwGEI04eP">https://t.co/4xwGEI04eP</a><br><br>with <a href="https://twitter.com/HuaxiuYaoML?ref_src=twsrc%5Etfw">@HuaxiuYaoML</a>, <a href="https://twitter.com/zlj11112222?ref_src=twsrc%5Etfw">@zlj11112222</a> <a href="https://t.co/qkSOxTGO4k">pic.twitter.com/qkSOxTGO4k</a></p>&mdash; Chelsea Finn (@chelseabfinn) <a href="https://twitter.com/chelseabfinn/status/1402130263409192961?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. Shape As Points: A Differentiable Poisson Solver

Songyou Peng, Chiyu "Max" Jiang, Yiyi Liao, Michael Niemeyer, Marc Pollefeys, Andreas Geiger

- retweets: 812, favorites: 149 (06/09/2021 10:51:37)

- links: [abs](https://arxiv.org/abs/2106.03452) | [pdf](https://arxiv.org/pdf/2106.03452)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.GR](https://arxiv.org/list/cs.GR/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Shape As Points: A Differentiable Poisson Solver<br>pdf: <a href="https://t.co/h8tzSKTViu">https://t.co/h8tzSKTViu</a><br>abs: <a href="https://t.co/e1cMmpwnmZ">https://t.co/e1cMmpwnmZ</a><br><br>shape representation- interpretable, lightweight, yields HQ watertight meshes at much lower inference times compared to neural implicit representations<a href="https://twitter.com/songyoupeng?ref_src=twsrc%5Etfw">@songyoupeng</a> <a href="https://t.co/C94pg3jhxj">pic.twitter.com/C94pg3jhxj</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402129150673133570?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. Motion Planning Transformers: One Model to Plan Them All

Jacob J. Johnson, Linjun Li, Ahmed H. Qureshi, Michael C. Yip

- retweets: 576, favorites: 97 (06/09/2021 10:51:38)

- links: [abs](https://arxiv.org/abs/2106.02791) | [pdf](https://arxiv.org/pdf/2106.02791)
- [cs.RO](https://arxiv.org/list/cs.RO/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Motion Planning Transformers: One Model to Plan Them All<br>pdf: <a href="https://t.co/5T8NPyhukm">https://t.co/5T8NPyhukm</a><br>abs: <a href="https://t.co/4IQfPiTZan">https://t.co/4IQfPiTZan</a><br><br>identifies regions on map using transformers to provide attention to map areas likely to include best path, local planners to generate final collision-free path <a href="https://t.co/ZkhS88XWHg">pic.twitter.com/ZkhS88XWHg</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402072082561765378?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. Deep Medial Fields

Daniel Rebain, Ke Li, Vincent Sitzmann, Soroosh Yazdani, Kwang Moo Yi, Andrea Tagliasacchi

- retweets: 422, favorites: 95 (06/09/2021 10:51:38)

- links: [abs](https://arxiv.org/abs/2106.03804) | [pdf](https://arxiv.org/pdf/2106.03804)
- [cs.GR](https://arxiv.org/list/cs.GR/recent) | [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Deep Medial Fields<br>pdf: <a href="https://t.co/4A0MYSgusu">https://t.co/4A0MYSgusu</a><br>abs: <a href="https://t.co/yUndmxSM1t">https://t.co/yUndmxSM1t</a><br><br>an implicit representation of the local thickness, that expands the capacity of implicit representations for 3D geometry <a href="https://t.co/sneCJPQnZD">pic.twitter.com/sneCJPQnZD</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402079324031881216?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. 3DB: A Framework for Debugging Computer Vision Models

Guillaume Leclerc, Hadi Salman, Andrew Ilyas, Sai Vemprala, Logan Engstrom, Vibhav Vineet, Kai Xiao, Pengchuan Zhang, Shibani Santurkar, Greg Yang, Ashish Kapoor, Aleksander Madry

- retweets: 445, favorites: 71 (06/09/2021 10:51:39)

- links: [abs](https://arxiv.org/abs/2106.03805) | [pdf](https://arxiv.org/pdf/2106.03805)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Introducing 3DB, a framework for debugging models using 3D rendering. Reproduce your favorite robustness analyses or design your own analyses/experiments in just a few lines of code! (1/3)<br>Paper: <a href="https://t.co/lYdjdEAAKS">https://t.co/lYdjdEAAKS</a><br>Code: <a href="https://t.co/apgPypgolQ">https://t.co/apgPypgolQ</a><br>Blog: <a href="https://t.co/69HBeutEt9">https://t.co/69HBeutEt9</a> <a href="https://t.co/L2f2MfMEsI">pic.twitter.com/L2f2MfMEsI</a></p>&mdash; Aleksander Madry (@aleks_madry) <a href="https://twitter.com/aleks_madry/status/1402332019326136322?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Check out *3DB*: our new tool for debugging computer vision models via 3D simulation! A year-long effort from our lab <a href="https://twitter.com/MIT?ref_src=twsrc%5Etfw">@MIT</a> and <a href="https://twitter.com/MSFTResearch?ref_src=twsrc%5Etfw">@MSFTResearch</a>. <a href="https://t.co/KoUxwot5ZR">https://t.co/KoUxwot5ZR</a><br><br>We have extensive demos, docs, code and blogpost!<a href="https://t.co/DVXUbf7U2J">https://t.co/DVXUbf7U2J</a> <a href="https://t.co/wj26QXNafG">https://t.co/wj26QXNafG</a></p>&mdash; Hadi Salman (@hadisalmanX) <a href="https://twitter.com/hadisalmanX/status/1402357324417732619?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 8. Exploring the Limits of Out-of-Distribution Detection

Stanislav Fort, Jie Ren, Balaji Lakshminarayanan

- retweets: 361, favorites: 69 (06/09/2021 10:51:40)

- links: [abs](https://arxiv.org/abs/2106.03004) | [pdf](https://arxiv.org/pdf/2106.03004)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Exploring the Limits of Out-of-Distribution Detection<br>pdf: <a href="https://t.co/9WrKBri4PQ">https://t.co/9WrKBri4PQ</a><br>abs: <a href="https://t.co/bZPjf0mckf">https://t.co/bZPjf0mckf</a><br><br>fine-tuning large-scale pre-trained transformers and using few-shot outlier exposure can significantly improve the SOTA <a href="https://t.co/Ucorh8UazN">pic.twitter.com/Ucorh8UazN</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402070553360572418?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer

Zilong Huang, Youcheng Ben, Guozhong Luo, Pei Cheng, Gang Yu, Bin Fu

- retweets: 360, favorites: 61 (06/09/2021 10:51:40)

- links: [abs](https://arxiv.org/abs/2106.03650) | [pdf](https://arxiv.org/pdf/2106.03650)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Shuffle Transformer: Rethinking Spatial Shuffle for<br>Vision Transformer<br>pdf: <a href="https://t.co/qkqHXKWpLu">https://t.co/qkqHXKWpLu</a><br>abs: <a href="https://t.co/VpAssMY0Ec">https://t.co/VpAssMY0Ec</a> <a href="https://t.co/JQYVlUPeoO">pic.twitter.com/JQYVlUPeoO</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402161182388146178?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 10. Learning to Efficiently Sample from Diffusion Probabilistic Models

Daniel Watson, Jonathan Ho, Mohammad Norouzi, William Chan

- retweets: 232, favorites: 109 (06/09/2021 10:51:40)

- links: [abs](https://arxiv.org/abs/2106.03802) | [pdf](https://arxiv.org/pdf/2106.03802)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Learning to Efficiently Sample from Diffusion Probabilistic Models<br><br>Discovers inference time schedules requiring as few as 32 refinement steps, while sacrificing less than 0.1 bits per dimension compared to the default 4,000 steps used on ImageNet 64x64.<a href="https://t.co/cPjuCNKqh8">https://t.co/cPjuCNKqh8</a> <a href="https://t.co/QB2S1HKMst">pic.twitter.com/QB2S1HKMst</a></p>&mdash; Aran Komatsuzaki (@arankomatsuzaki) <a href="https://twitter.com/arankomatsuzaki/status/1402072048642392064?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Learning to Efficiently Sample from Diffusion Probabilistic Models<br>pdf: <a href="https://t.co/FiucHSsuLR">https://t.co/FiucHSsuLR</a><br>abs: <a href="https://t.co/KvXqT2OmRp">https://t.co/KvXqT2OmRp</a><br><br>a novel and efficient dynamic programming algorithm to discover the optimal inference schedule for a pre-trained DDPM <a href="https://t.co/acIRp5v5j3">pic.twitter.com/acIRp5v5j3</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402075897566486528?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 11. A Variational Perspective on Diffusion-Based Generative Models and Score  Matching

Chin-Wei Huang, Jae Hyun Lim, Aaron Courville

- retweets: 182, favorites: 92 (06/09/2021 10:51:41)

- links: [abs](https://arxiv.org/abs/2106.02808) | [pdf](https://arxiv.org/pdf/2106.02808)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Super excited to share our new theory paper on connecting diffusion models &amp; score matching from a variational perspective (i.e. likelihood training)!<a href="https://t.co/M7rcU0dieI">https://t.co/M7rcU0dieI</a><br><br>We derive a new ELBO for general continuous-time diffusion models.<br>w/ <a href="https://twitter.com/jaehyunlim0606?ref_src=twsrc%5Etfw">@jaehyunlim0606</a> &amp; <a href="https://twitter.com/AaronCourville?ref_src=twsrc%5Etfw">@AaronCourville</a> <a href="https://t.co/NLynQX38wk">pic.twitter.com/NLynQX38wk</a></p>&mdash; Chin-Wei Huang (@chinwei_h) <a href="https://twitter.com/chinwei_h/status/1402251145255477254?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 12. Self-Damaging Contrastive Learning

Ziyu Jiang, Tianlong Chen, Bobak Mortazavi, Zhangyang Wang

- retweets: 195, favorites: 70 (06/09/2021 10:51:41)

- links: [abs](https://arxiv.org/abs/2106.02990) | [pdf](https://arxiv.org/pdf/2106.02990)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Self-Damaging Contrastive Learning<br>pdf: <a href="https://t.co/wHoD6UJVoT">https://t.co/wHoD6UJVoT</a><br>abs: <a href="https://t.co/cBy0btgmR0">https://t.co/cBy0btgmR0</a><br>github: <a href="https://t.co/AzLq4utoiX">https://t.co/AzLq4utoiX</a> <a href="https://t.co/DnutaOKrje">pic.twitter.com/DnutaOKrje</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402321992091635717?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 13. BayesIMP: Uncertainty Quantification for Causal Data Fusion

Siu Lun Chau, Jean-Fran√ßois Ton, Javier Gonz√°lez, Yee Whye Teh, Dino Sejdinovic

- retweets: 182, favorites: 65 (06/09/2021 10:51:42)

- links: [abs](https://arxiv.org/abs/2106.03477) | [pdf](https://arxiv.org/pdf/2106.03477)
- [stat.ML](https://arxiv.org/list/stat.ML/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Interested in Kernel Methods, Causal Inference and Uncertainty quantification?<br><br>In our newest work we introduce BayesIMP: Uncertainty Quantification for Causal Data Fusion !<a href="https://t.co/trn8cfk8dM">https://t.co/trn8cfk8dM</a><br><br>Big thanks to <a href="https://twitter.com/Chau9991?ref_src=twsrc%5Etfw">@Chau9991</a> <a href="https://twitter.com/javiergonzh?ref_src=twsrc%5Etfw">@javiergonzh</a> <a href="https://twitter.com/yeewhye?ref_src=twsrc%5Etfw">@yeewhye</a> <a href="https://twitter.com/sejDino?ref_src=twsrc%5Etfw">@sejDino</a>  1/n <a href="https://t.co/34TiJvMKeG">pic.twitter.com/34TiJvMKeG</a></p>&mdash; Jean-Fran√ßois Ton (@jeanfrancois287) <a href="https://twitter.com/jeanfrancois287/status/1402226662029279232?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 14. Multi-chart flows

Dimitris Kalatzis, Johan Ziruo Ye, Jesper Wohlert, S√∏ren Hauberg

- retweets: 156, favorites: 80 (06/09/2021 10:51:42)

- links: [abs](https://arxiv.org/abs/2106.03500) | [pdf](https://arxiv.org/pdf/2106.03500)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">New preprint on normalizing flows! <a href="https://t.co/TImKXBP88v">https://t.co/TImKXBP88v</a><br><br>Question: can you use normalizing flows to learn a density on a smooth manifold along with the manifold structure?<br><br>TL;DR: You can, if you know how to use them ;)<br><br>A thread.</p>&mdash; Dimitris Kalatzis (@__DiracDelta) <a href="https://twitter.com/__DiracDelta/status/1402350186341572612?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 15. RegionViT: Regional-to-Local Attention for Vision Transformers

Chun-Fu Chen, Rameswar Panda, Quanfu Fan

- retweets: 169, favorites: 36 (06/09/2021 10:51:42)

- links: [abs](https://arxiv.org/abs/2106.02689) | [pdf](https://arxiv.org/pdf/2106.02689)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">RegionViT: Regional-to-Local Attention for Vision Transformers<br>pdf: <a href="https://t.co/fEWYlYo8QI">https://t.co/fEWYlYo8QI</a><br>abs: <a href="https://t.co/d9Zm3DIZei">https://t.co/d9Zm3DIZei</a><br><br>architecture that adopts the pyramid structure and employ a novel regional-to-local attention rather than global self-attention in vision transformers <a href="https://t.co/rIa607LudC">pic.twitter.com/rIa607LudC</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402071317151731720?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 16. Photonic Differential Privacy with Direct Feedback Alignment

Ruben Ohana, Hamlet J. Medina Ruiz, Julien Launay, Alessandro Cappelli, Iacopo Poli, Liva Ralaivola, Alain Rakotomamonjy

- retweets: 149, favorites: 34 (06/09/2021 10:51:43)

- links: [abs](https://arxiv.org/abs/2106.03645) | [pdf](https://arxiv.org/pdf/2106.03645)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.CR](https://arxiv.org/list/cs.CR/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üí•Differential privacy with <a href="https://twitter.com/LightOnIO?ref_src=twsrc%5Etfw">@LightOnIO</a> OPUs? Yes, you can!<br>In collaboration with <a href="https://twitter.com/CriteoAILab?ref_src=twsrc%5Etfw">@CriteoAILab</a> here is &quot;Photonic Differential Privacy with Direct Feedback Alignment&quot; by <a href="https://twitter.com/oharub?ref_src=twsrc%5Etfw">@oharub</a> Hamlet Ruiz <a href="https://twitter.com/slippylolo?ref_src=twsrc%5Etfw">@slippylolo</a> <a href="https://twitter.com/achapeau1?ref_src=twsrc%5Etfw">@achapeau1</a> <a href="https://twitter.com/iacopo_poli?ref_src=twsrc%5Etfw">@iacopo_poli</a> <a href="https://twitter.com/LivaRalaivola?ref_src=twsrc%5Etfw">@LivaRalaivola</a> <a href="https://twitter.com/rakotal1?ref_src=twsrc%5Etfw">@rakotal1</a> <a href="https://t.co/BV1GGyh7jG">https://t.co/BV1GGyh7jG</a> <a href="https://t.co/t8OEj6LKxX">pic.twitter.com/t8OEj6LKxX</a></p>&mdash; LightOn (@LightOnIO) <a href="https://twitter.com/LightOnIO/status/1402190100302282755?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 17. Meta-research on COVID-19: An overview of the early trends

Giovanni Colavizza

- retweets: 144, favorites: 20 (06/09/2021 10:51:43)

- links: [abs](https://arxiv.org/abs/2106.02961) | [pdf](https://arxiv.org/pdf/2106.02961)
- [cs.DL](https://arxiv.org/list/cs.DL/recent) | [cs.CY](https://arxiv.org/list/cs.CY/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">New pre-print out: ‚ÄúMeta-research on COVID-19: An overview of the early trends‚Äù <a href="https://t.co/67H2493My2">https://t.co/67H2493My2</a><br><br>I review science studies, scientometrics and related meta-research work on COVID-19‚Äôs impact on research and researchers, and their responses.<br><br>Main findings follow üëá</p>&mdash; Giovanni Colavizza (@giovanni1085) <a href="https://twitter.com/giovanni1085/status/1402198537622990851?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 18. Uformer: A General U-Shaped Transformer for Image Restoration

Zhendong Wang, Xiaodong Cun, Jianmin Bao, Jianzhuang Liu

- retweets: 81, favorites: 64 (06/09/2021 10:51:44)

- links: [abs](https://arxiv.org/abs/2106.03106) | [pdf](https://arxiv.org/pdf/2106.03106)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Uformer: A General U-Shaped Transformer for Image Restoration<br>pdf: <a href="https://t.co/VHxgIBI0yr">https://t.co/VHxgIBI0yr</a><br>abs: <a href="https://t.co/xqHomTEIzQ">https://t.co/xqHomTEIzQ</a><br><br>achieves sota performance on several tasks, including denoising, deraining, deblurring, and demoireing <a href="https://t.co/1JC2rSIMsx">pic.twitter.com/1JC2rSIMsx</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402080755505848321?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 19. Control-Oriented Model-Based Reinforcement Learning with Implicit  Differentiation

Evgenii Nikishin, Romina Abachi, Rishabh Agarwal, Pierre-Luc Bacon

- retweets: 69, favorites: 65 (06/09/2021 10:51:44)

- links: [abs](https://arxiv.org/abs/2106.03273) | [pdf](https://arxiv.org/pdf/2106.03273)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We present Optimal Model Design (OMD) ‚Äî a model-based RL algorithm that trains the model to **directly** optimize the sum of rewards instead of proxies to the agent‚Äôs goal (e.g. likelihood p(s‚Äô, r | s, a)).<a href="https://t.co/RfMw9n6FiC">https://t.co/RfMw9n6FiC</a><br>With <a href="https://twitter.com/rom72aba?ref_src=twsrc%5Etfw">@rom72aba</a>, <a href="https://twitter.com/agarwl_?ref_src=twsrc%5Etfw">@agarwl_</a>, <a href="https://twitter.com/pierrelux?ref_src=twsrc%5Etfw">@pierrelux</a><br>1/9 üßµ</p>&mdash; Evgenii Nikishin (@nikishin_evg) <a href="https://twitter.com/nikishin_evg/status/1402279613355659267?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Control-Oriented Model-Based Reinforcement Learning with Implicit Differentiation<br>pdf: <a href="https://t.co/bgwUFDdsyN">https://t.co/bgwUFDdsyN</a><br>abs: <a href="https://t.co/8XAH6z0I9k">https://t.co/8XAH6z0I9k</a><br><br>a method for learning control-oriented models that<br>addresses the shortcomings of likelihood-based MBRL approaches <a href="https://t.co/awLkPwHUic">pic.twitter.com/awLkPwHUic</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402087840046006273?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 20. Refiner: Refining Self-attention for Vision Transformers

Daquan Zhou, Yujun Shi, Bingyi Kang, Weihao Yu, Zihang Jiang, Yuan Li, Xiaojie Jin, Qibin Hou, Jiashi Feng

- retweets: 81, favorites: 22 (06/09/2021 10:51:45)

- links: [abs](https://arxiv.org/abs/2106.03714) | [pdf](https://arxiv.org/pdf/2106.03714)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Refiner: Refining Self-attention for Vision Transformers<br>pdf: <a href="https://t.co/IgvB5eeSTQ">https://t.co/IgvB5eeSTQ</a><br>abs: <a href="https://t.co/olYwqKm0Sp">https://t.co/olYwqKm0Sp</a><br><br>augments the self-attention of ViTs by attention expansion and distributed local attention <a href="https://t.co/D4EbMsDutd">pic.twitter.com/D4EbMsDutd</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402083594106019842?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 21. Itihasa: A large-scale corpus for Sanskrit to English translation

Rahul Aralikatte, Miryam de Lhoneux, Anoop Kunchukuttan, Anders S√∏gaard

- retweets: 56, favorites: 39 (06/09/2021 10:51:45)

- links: [abs](https://arxiv.org/abs/2106.03269) | [pdf](https://arxiv.org/pdf/2106.03269)
- [cs.CL](https://arxiv.org/list/cs.CL/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Announcing Itihasa, a large-scale Sanskrit-English translation corpus. This work is very close to my heart and I have been working on it for more than a year now. <a href="https://t.co/QHvpuSJreT">https://t.co/QHvpuSJreT</a> (1/)</p>&mdash; Rahul (@rahul_a_r) <a href="https://twitter.com/rahul_a_r/status/1402282494683238402?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 22. Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation

Dongchan Min, Dong Bok Lee, Eunho Yang, Sung Ju Hwang

- retweets: 56, favorites: 37 (06/09/2021 10:51:45)

- links: [abs](https://arxiv.org/abs/2106.03153) | [pdf](https://arxiv.org/pdf/2106.03153)
- [eess.AS](https://arxiv.org/list/eess.AS/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.SD](https://arxiv.org/list/cs.SD/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation<br>pdf: <a href="https://t.co/dyYv0OzXSG">https://t.co/dyYv0OzXSG</a><br>abs: <a href="https://t.co/mqKD7pyifb">https://t.co/mqKD7pyifb</a><br>project page: <a href="https://t.co/sBMKfftK2L">https://t.co/sBMKfftK2L</a> <a href="https://t.co/tj9hBf7Rh7">pic.twitter.com/tj9hBf7Rh7</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402085023155634179?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 23. SIMONe: View-Invariant, Temporally-Abstracted Object Representations via  Unsupervised Video Decomposition

Rishabh Kabra, Daniel Zoran, Goker Erdogan, Loic Matthey, Antonia Creswell, Matthew Botvinick, Alexander Lerchner, Christopher P. Burgess

- retweets: 42, favorites: 43 (06/09/2021 10:51:46)

- links: [abs](https://arxiv.org/abs/2106.03849) | [pdf](https://arxiv.org/pdf/2106.03849)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">SIMONe: View-Invariant, Temporally-Abstracted<br>Object Representations via Unsupervised Video Decomposition<br>pdf: <a href="https://t.co/Tnjm7UMynw">https://t.co/Tnjm7UMynw</a><br>abs: <a href="https://t.co/960ki3Z7a4">https://t.co/960ki3Z7a4</a><br>project page: <a href="https://t.co/A5TxvNM8gM">https://t.co/A5TxvNM8gM</a> <a href="https://t.co/KuwamRedm9">pic.twitter.com/KuwamRedm9</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402090850851622917?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 24. RedditBias: A Real-World Resource for Bias Evaluation and Debiasing of  Conversational Language Models

Soumya Barikeri, Anne Lauscher, Ivan Vuliƒá, Goran Glava≈°

- retweets: 56, favorites: 27 (06/09/2021 10:51:46)

- links: [abs](https://arxiv.org/abs/2106.03521) | [pdf](https://arxiv.org/pdf/2106.03521)
- [cs.CL](https://arxiv.org/list/cs.CL/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The RedditBias paper is available now: we describe a conversational data set grounded in actual human conversations from Reddit and couple bias evaluation with model capability evaluation in dialog tasks after model debiasing.ü§ñ <a href="https://twitter.com/gg42554?ref_src=twsrc%5Etfw">@gg42554</a> <a href="https://twitter.com/licwu?ref_src=twsrc%5Etfw">@licwu</a> <a href="https://twitter.com/dwsunima?ref_src=twsrc%5Etfw">@dwsunima</a>   <a href="https://t.co/31a0Z5W8Yy">https://t.co/31a0Z5W8Yy</a></p>&mdash; Anne Lauscher (@anne_lauscher) <a href="https://twitter.com/anne_lauscher/status/1402177365481041920?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 25. Recovery Analysis for Plug-and-Play Priors using the Restricted  Eigenvalue Condition

Jiaming Liu, M. Salman Asif, Brendt Wohlberg, Ulugbek S. Kamilov

- retweets: 48, favorites: 31 (06/09/2021 10:51:46)

- links: [abs](https://arxiv.org/abs/2106.03668) | [pdf](https://arxiv.org/pdf/2106.03668)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [eess.IV](https://arxiv.org/list/eess.IV/recent) | [eess.SP](https://arxiv.org/list/eess.SP/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Recovery Analysis for Plug-and-Play Priors using the Restricted Eigenvalue Condition&quot; is out on arXiv. <br><br>Read it here: <a href="https://t.co/NiP0jt49HV">https://t.co/NiP0jt49HV</a>.<br><br>We don&#39;t propose any new algorithms, so what is the goal? <a href="https://t.co/SqHbNCFDxB">pic.twitter.com/SqHbNCFDxB</a></p>&mdash; Ulugbek S. Kamilov (@ukmlv) <a href="https://twitter.com/ukmlv/status/1402234840481730561?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 26. Learnable Fourier Features for Multi-DimensionalSpatial Positional  Encoding

Yang Li, Si Si, Gang Li, Cho-Jui Hsieh, Samy Bengio

- retweets: 30, favorites: 29 (06/09/2021 10:51:46)

- links: [abs](https://arxiv.org/abs/2106.02795) | [pdf](https://arxiv.org/pdf/2106.02795)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Learnable Fourier Features for Multi-Dimensional Spatial Positional Encoding<br>pdf: <a href="https://t.co/H3RKW8P6gE">https://t.co/H3RKW8P6gE</a><br>abs: <a href="https://t.co/auUmvMqqMd">https://t.co/auUmvMqqMd</a><br><br>a novel positional encoding method based on learnable Fourier features <a href="https://t.co/eE5d5lRlja">pic.twitter.com/eE5d5lRlja</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402074947732840449?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 27. Lawvere-Tierney topologies for computability theorists

Takayuki Kihara

- retweets: 49, favorites: 9 (06/09/2021 10:51:47)

- links: [abs](https://arxiv.org/abs/2106.03061) | [pdf](https://arxiv.org/pdf/2106.03061)
- [math.LO](https://arxiv.org/list/math.LO/recent) | [cs.LO](https://arxiv.org/list/cs.LO/recent) | [math.CT](https://arxiv.org/list/math.CT/recent)






# 28. Hierarchical Video Generation for Complex Data

Lluis Castrejon, Nicolas Ballas, Aaron Courville

- retweets: 20, favorites: 30 (06/09/2021 10:51:47)

- links: [abs](https://arxiv.org/abs/2106.02719) | [pdf](https://arxiv.org/pdf/2106.02719)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Hierarchical Video Generation for Complex Data<br>pdf: <a href="https://t.co/zKMauHlSMO">https://t.co/zKMauHlSMO</a><br>abs: <a href="https://t.co/DE4xHaOqgg">https://t.co/DE4xHaOqgg</a><br><br>model generates a low resolution video, establishing the<br>global scene structure, that is then refined by subsequent levels in the hierarchy <a href="https://t.co/KiyY06ioHa">pic.twitter.com/KiyY06ioHa</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1402122027746660353?ref_src=twsrc%5Etfw">June 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



