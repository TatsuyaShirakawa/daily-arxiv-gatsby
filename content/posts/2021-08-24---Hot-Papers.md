---
title: Hot Papers 2021-08-24
date: 2021-08-25T08:15:57.Z
template: "post"
draft: false
slug: "hot-papers-2021-08-24"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2021-08-24"
socialImage: "/media/flying-marine.jpg"

---

# 1. Towards Explainable Fact Checking

Isabelle Augenstein

- retweets: 702, favorites: 200 (08/25/2021 08:15:57)

- links: [abs](https://arxiv.org/abs/2108.10274) | [pdf](https://arxiv.org/pdf/2108.10274)
- [cs.CL](https://arxiv.org/list/cs.CL/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

The past decade has seen a substantial rise in the amount of mis- and disinformation online, from targeted disinformation campaigns to influence politics, to the unintentional spreading of misinformation about public health. This development has spurred research in the area of automatic fact checking, from approaches to detect check-worthy claims and determining the stance of tweets towards claims, to methods to determine the veracity of claims given evidence documents. These automatic methods are often content-based, using natural language processing methods, which in turn utilise deep neural networks to learn higher-order features from text in order to make predictions. As deep neural networks are black-box models, their inner workings cannot be easily explained. At the same time, it is desirable to explain how they arrive at certain decisions, especially if they are to be used for decision making. While this has been known for some time, the issues this raises have been exacerbated by models increasing in size, and by EU legislation requiring models to be used for decision making to provide explanations, and, very recently, by legislation requiring online platforms operating in the EU to provide transparent reporting on their services. Despite this, current solutions for explainability are still lacking in the area of fact checking. This thesis presents my research on automatic fact checking, including claim check-worthiness detection, stance detection and veracity prediction. Its contributions go beyond fact checking, with the thesis proposing more general machine learning solutions for natural language processing in the area of learning with limited labelled data. Finally, the thesis presents some first solutions for explainable fact checking.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üìúI&#39;m happy to share that my second doctoral thesis (doktordisputats, habilitation) titled &quot;Towards Explainable Fact Checking&quot; has been accepted for defence (without revisions)! In case anyone is curious, you can read it here: <a href="https://t.co/qOSJM7wZ83">https://t.co/qOSJM7wZ83</a><a href="https://twitter.com/hashtag/NLProc?src=hash&amp;ref_src=twsrc%5Etfw">#NLProc</a></p>&mdash; Isabelle Augenstein (@IAugenstein) <a href="https://twitter.com/IAugenstein/status/1430034274544234508?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. New Trends in Quantum Machine Learning

Lorenzo Buffoni, Filippo Caruso

- retweets: 308, favorites: 181 (08/25/2021 08:15:57)

- links: [abs](https://arxiv.org/abs/2108.09664) | [pdf](https://arxiv.org/pdf/2108.09664)
- [quant-ph](https://arxiv.org/list/quant-ph/recent) | [cond-mat.dis-nn](https://arxiv.org/list/cond-mat.dis-nn/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

Here we will give a perspective on new possible interplays between Machine Learning and Quantum Physics, including also practical cases and applications. We will explore the ways in which machine learning could benefit from new quantum technologies and algorithms to find new ways to speed up their computations by breakthroughs in physical hardware, as well as to improve existing models or devise new learning schemes in the quantum domain. Moreover, there are lots of experiments in quantum physics that do generate incredible amounts of data and machine learning would be a great tool to analyze those and make predictions, or even control the experiment itself. On top of that, data visualization techniques and other schemes borrowed from machine learning can be of great use to theoreticians to have better intuition on the structure of complex manifolds or to make predictions on theoretical models. This new research field, named as Quantum Machine Learning, is very rapidly growing since it is expected to provide huge advantages over its classical counterpart and deeper investigations are timely needed since they can be already tested on the already commercially available quantum machines.

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">ÈáèÂ≠êÊ©üÊ¢∞Â≠¶Áøí„ÅÆÊúÄËøë„ÅÆ„Éà„É¨„É≥„Éâ„Å´Èñ¢„Åô„Çã„Çµ„Éº„Éô„Ç§Ë´ñÊñá<br>„Åù„Åì„Åæ„ÅßÈï∑„Åè„Å™„ÅÑ&amp;ÁêÜË´ñÁöÑ„Å™Ë©±„ÅØ„ÅÇ„Åæ„ÇäÂá∫„Å¶„Åì„Å™„ÅÑ„ÅÆ„Åß„ÄÅË™≠„Åø„ÇÑ„Åô„Åù„ÅÜ<br>&quot;New Trends in Quantum Machine Learning&quot;<a href="https://t.co/Gy7jcuUluL">https://t.co/Gy7jcuUluL</a></p>&mdash; „Åà„Çã„Ç®„É´ (@ImAI_Eruel) <a href="https://twitter.com/ImAI_Eruel/status/1430102187636445186?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. How Cute is Pikachu? Gathering and Ranking Pok√©mon Properties from  Data with Pok√©mon Word Embeddings

Mika H√§m√§l√§inen, Khalid Alnajjar, Niko Partanen

- retweets: 380, favorites: 54 (08/25/2021 08:15:57)

- links: [abs](https://arxiv.org/abs/2108.09546) | [pdf](https://arxiv.org/pdf/2108.09546)
- [cs.CL](https://arxiv.org/list/cs.CL/recent)

We present different methods for obtaining descriptive properties automatically for the 151 original Pok\'emon. We train several different word embeddings models on a crawled Pok\'emon corpus, and use them to rank automatically English adjectives based on how characteristic they are to a given Pok\'emon. Based on our experiments, it is better to train a model with domain specific data than to use a pretrained model. Word2Vec produces less noise in the results than fastText model. Furthermore, we expand the list of properties for each Pok\'emon automatically. However, none of the methods is spot on and there is a considerable amount of noise in the different semantic models. Our models have been released on Zenodo.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">How Cute is Pikachu? Gathering and Ranking Pokemon Properties from Data with Pokemon Word Embeddings<br>pdf: <a href="https://t.co/cHPwyR3iXF">https://t.co/cHPwyR3iXF</a><br>abs: <a href="https://t.co/3XMH1KwTTQ">https://t.co/3XMH1KwTTQ</a> <a href="https://t.co/5NROR7aLz5">pic.twitter.com/5NROR7aLz5</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1429983828018356228?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. How Can Increased Randomness in Stochastic Gradient Descent Improve  Generalization?

Arwen V. Bradley, Carlos Alberto Gomez-Uribe

- retweets: 289, favorites: 94 (08/25/2021 08:15:57)

- links: [abs](https://arxiv.org/abs/2108.09507) | [pdf](https://arxiv.org/pdf/2108.09507)
- [stat.ML](https://arxiv.org/list/stat.ML/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

Recent works report that increasing the learning rate or decreasing the minibatch size in stochastic gradient descent (SGD) can improve test set performance. We argue this is expected under some conditions in models with a loss function with multiple local minima. Our main contribution is an approximate but analytical approach inspired by methods in Physics to study the role of the SGD learning rate and batch size in generalization. We characterize test set performance under a shift between the training and test data distributions for loss functions with multiple minima. The shift can simply be due to sampling, and is therefore typically present in practical applications. We show that the resulting shift in local minima worsens test performance by picking up curvature, implying that generalization improves by selecting wide and/or little-shifted local minima. We then specialize to SGD, and study its test performance under stationarity. Because obtaining the exact stationary distribution of SGD is intractable, we derive a Fokker-Planck approximation of SGD and obtain its stationary distribution instead. This process shows that the learning rate divided by the minibatch size plays a role analogous to temperature in statistical mechanics, and implies that SGD, including its stationary distribution, is largely invariant to changes in learning rate or batch size that leave its temperature constant. We show that increasing SGD temperature encourages the selection of local minima with lower curvature, and can enable better generalization. We provide experiments on CIFAR10 demonstrating the temperature invariance of SGD, improvement of the test loss as SGD temperature increases, and quantifying the impact of sampling versus domain shift in driving this effect. Finally, we present synthetic experiments showing how our theory applies in a simplified loss with two local minima.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">How Can Increased Randomness in Stochastic Gradient Descent Improve Generalization?<br>pdf: <a href="https://t.co/Jsj1hpi3vB">https://t.co/Jsj1hpi3vB</a><br>abs: <a href="https://t.co/nEGOGZ2Z8v">https://t.co/nEGOGZ2Z8v</a> <a href="https://t.co/weTbqMbQbF">pic.twitter.com/weTbqMbQbF</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1430016391512576004?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. Learning Signed Distance Field for Multi-view Surface Reconstruction

Jingyang Zhang, Yao Yao, Long Quan

- retweets: 233, favorites: 113 (08/25/2021 08:15:57)

- links: [abs](https://arxiv.org/abs/2108.09964) | [pdf](https://arxiv.org/pdf/2108.09964)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)

Recent works on implicit neural representations have shown promising results for multi-view surface reconstruction. However, most approaches are limited to relatively simple geometries and usually require clean object masks for reconstructing complex and concave objects. In this work, we introduce a novel neural surface reconstruction framework that leverages the knowledge of stereo matching and feature consistency to optimize the implicit surface representation. More specifically, we apply a signed distance field (SDF) and a surface light field to represent the scene geometry and appearance respectively. The SDF is directly supervised by geometry from stereo matching, and is refined by optimizing the multi-view feature consistency and the fidelity of rendered images. Our method is able to improve the robustness of geometry estimation and support reconstruction of complex scene topologies. Extensive experiments have been conducted on DTU, EPFL and Tanks and Temples datasets. Compared to previous state-of-the-art methods, our method achieves better mesh reconstruction in wide open scenes without masks as input.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Learning Signed Distance Field for Multi-view Surface Reconstruction<br>pdf: <a href="https://t.co/Bx30rw96tr">https://t.co/Bx30rw96tr</a><br>abs: <a href="https://t.co/r0kVyPiqeN">https://t.co/r0kVyPiqeN</a> <a href="https://t.co/8aWVoDjITF">pic.twitter.com/8aWVoDjITF</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1429992779372011525?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. Beyond Linear Algebra

Bernd Sturmfels

- retweets: 201, favorites: 67 (08/25/2021 08:15:57)

- links: [abs](https://arxiv.org/abs/2108.09494) | [pdf](https://arxiv.org/pdf/2108.09494)
- [math.AG](https://arxiv.org/list/math.AG/recent) | [cs.SC](https://arxiv.org/list/cs.SC/recent) | [math.OC](https://arxiv.org/list/math.OC/recent) | [math.ST](https://arxiv.org/list/math.ST/recent)

Our title challenges the reader to venture beyond linear algebra in designing models and in thinking about numerical algorithms for identifying solutions. This article accompanies the author's lecture at the International Congress of Mathematicians 2022. It covers recent advances in the study of critical point equations in optimization and statistics, and it explores the role of nonlinear algebra in the study of linear PDE with constant coefficients.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;Beyond Linear Algebra&quot; (by Bernd Sturmfels): <a href="https://t.co/AqyHaVV75O">https://t.co/AqyHaVV75O</a><br><br>&quot;This article accompanies the author&#39;s lecture at the International Congress of Mathematicians 2022.&quot;</p>&mdash; DynamicalSystemsSIAM (@DynamicsSIAM) <a href="https://twitter.com/DynamicsSIAM/status/1429988346260967424?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. C5T5: Controllable Generation of Organic Molecules with Transformers

Daniel Rothchild, Alex Tamkin, Julie Yu, Ujval Misra, Joseph Gonzalez

- retweets: 210, favorites: 35 (08/25/2021 08:15:58)

- links: [abs](https://arxiv.org/abs/2108.10307) | [pdf](https://arxiv.org/pdf/2108.10307)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)

Methods for designing organic materials with desired properties have high potential impact across fields such as medicine, renewable energy, petrochemical engineering, and agriculture. However, using generative modeling to design substances with desired properties is difficult because candidate compounds must satisfy multiple constraints, including synthetic accessibility and other metrics that are intuitive to domain experts but challenging to quantify. We propose C5T5, a novel self-supervised pretraining method that enables transformers to make zero-shot select-and-replace edits, altering organic substances towards desired property values. C5T5 operates on IUPAC names -- a standardized molecular representation that intuitively encodes rich structural information for organic chemists but that has been largely ignored by the ML community. Our technique requires no edited molecule pairs to train and only a rough estimate of molecular properties, and it has the potential to model long-range dependencies and symmetric molecular structures more easily than graph-based methods. C5T5 also provides a powerful interface to domain experts: it grants users fine-grained control over the generative process by selecting and replacing IUPAC name fragments, which enables experts to leverage their intuitions about structure-activity relationships. We demonstrate C5T5's effectiveness on four physical properties relevant for drug discovery, showing that it learns successful and chemically intuitive strategies for altering molecules towards desired property values.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">C5T5: Controllable Generation of Organic Molecules<br>with Transformers<br>abs: <a href="https://t.co/ickydlVxLU">https://t.co/ickydlVxLU</a><br><br>a novel selfsupervised pretraining method that enables transformers to make zero-shot select and-replace edits, altering organic substances towards desired property values <a href="https://t.co/UB5D0cvZG9">pic.twitter.com/UB5D0cvZG9</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1429974674755162114?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 8. 3D Reconstruction from public webcams

Tianyu Wu, Konrad Schindler, Cenek Albl

- retweets: 152, favorites: 80 (08/25/2021 08:15:58)

- links: [abs](https://arxiv.org/abs/2108.09476) | [pdf](https://arxiv.org/pdf/2108.09476)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)

In this paper, we investigate the possibility of reconstructing the 3D geometry of a scene captured by multiple webcams. The number of publicly accessible webcams is already large and it is growing every day. A logical question arises - can we use this free source of data for something beyond leisure activities? The challenge is that no internal, external, or temporal calibration of these cameras is available. We show that using recent advances in computer vision, we successfully calibrate the cameras, perform 3D reconstructions of the static scene and also recover the 3D trajectories of moving objects.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">3D Reconstruction from public webcams<a href="https://t.co/bYNMBsZdfk">https://t.co/bYNMBsZdfk</a><br><br>Hey <a href="https://twitter.com/AmirRubin?ref_src=twsrc%5Etfw">@AmirRubin</a>, check out this 3D <a href="https://twitter.com/hashtag/computervision?src=hash&amp;ref_src=twsrc%5Etfw">#computervision</a> project which uses SuperGlue, a deep feature-based matcher‚Äîextremely useful for creating a robust <a href="https://twitter.com/hashtag/digitaltwin?src=hash&amp;ref_src=twsrc%5Etfw">#digitaltwin</a> of outdoor spaces. Thanks <a href="https://twitter.com/ducha_aiki?ref_src=twsrc%5Etfw">@ducha_aiki</a> for sharing! <a href="https://t.co/LtSeSRsLWD">pic.twitter.com/LtSeSRsLWD</a></p>&mdash; Tomasz Malisiewicz (@quantombone) <a href="https://twitter.com/quantombone/status/1430146858773630994?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">3D Reconstruction from public webcams<br>Tianyu Wu, Konrad Schindler, <a href="https://twitter.com/CenekAlbl?ref_src=twsrc%5Etfw">@CenekAlbl</a> <a href="https://twitter.com/ETH_en?ref_src=twsrc%5Etfw">@ETH_en</a> <br><br>tl;dr: one can estimate camera matrices P and get some 3d reconstruction from the webcams, using YOLO5, SuperGlue and CSRT tracker. <a href="https://t.co/lfldFsgQHi">https://t.co/lfldFsgQHi</a> <a href="https://t.co/wIJsGsyujq">pic.twitter.com/wIJsGsyujq</a></p>&mdash; Dmytro Mishkin (@ducha_aiki) <a href="https://twitter.com/ducha_aiki/status/1430131371025080321?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. SwinIR: Image Restoration Using Swin Transformer

Jingyun Liang, Jiezhang Cao, Guolei Sun, Kai Zhang, Luc Van Gool, Radu Timofte

- retweets: 156, favorites: 51 (08/25/2021 08:15:58)

- links: [abs](https://arxiv.org/abs/2108.10257) | [pdf](https://arxiv.org/pdf/2108.10257)
- [eess.IV](https://arxiv.org/list/eess.IV/recent) | [cs.CV](https://arxiv.org/list/cs.CV/recent)

Image restoration is a long-standing low-level vision problem that aims to restore high-quality images from low-quality images (e.g., downscaled, noisy and compressed images). While state-of-the-art image restoration methods are based on convolutional neural networks, few attempts have been made with Transformers which show impressive performance on high-level vision tasks. In this paper, we propose a strong baseline model SwinIR for image restoration based on the Swin Transformer. SwinIR consists of three parts: shallow feature extraction, deep feature extraction and high-quality image reconstruction. In particular, the deep feature extraction module is composed of several residual Swin Transformer blocks (RSTB), each of which has several Swin Transformer layers together with a residual connection. We conduct experiments on three representative tasks: image super-resolution (including classical, lightweight and real-world image super-resolution), image denoising (including grayscale and color image denoising) and JPEG compression artifact reduction. Experimental results demonstrate that SwinIR outperforms state-of-the-art methods on different tasks by $\textbf{up to 0.14$\sim$0.45dB}$, while the total number of parameters can be reduced by $\textbf{up to 67%}$.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">SwinIR: Image Restoration Using Swin Transformer<br>pdf: <a href="https://t.co/OR4uiFd7As">https://t.co/OR4uiFd7As</a><br>abs: <a href="https://t.co/9SfKIoR9Rq">https://t.co/9SfKIoR9Rq</a><br><br>outperforms sota methods on different tasks by up to 0.14‚àº0.45dB, while the total number of parameters can be reduced by up to 67% <a href="https://t.co/hZDJNQbF6i">pic.twitter.com/hZDJNQbF6i</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1429975579143647237?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 10. Patch2CAD: Patchwise Embedding Learning for In-the-Wild Shape Retrieval  from a Single Image

Weicheng Kuo, Anelia Angelova, Tsung-Yi Lin, Angela Dai

- retweets: 100, favorites: 39 (08/25/2021 08:15:58)

- links: [abs](https://arxiv.org/abs/2108.09368) | [pdf](https://arxiv.org/pdf/2108.09368)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)

3D perception of object shapes from RGB image input is fundamental towards semantic scene understanding, grounding image-based perception in our spatially 3-dimensional real-world environments. To achieve a mapping between image views of objects and 3D shapes, we leverage CAD model priors from existing large-scale databases, and propose a novel approach towards constructing a joint embedding space between 2D images and 3D CAD models in a patch-wise fashion -- establishing correspondences between patches of an image view of an object and patches of CAD geometry. This enables part similarity reasoning for retrieving similar CADs to a new image view without exact matches in the database. Our patch embedding provides more robust CAD retrieval for shape estimation in our end-to-end estimation of CAD model shape and pose for detected objects in a single input image. Experiments on in-the-wild, complex imagery from ScanNet show that our approach is more robust than state of the art in real-world scenarios without any exact CAD matches.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Patch2CAD: Patchwise Embedding Learning for In-the-Wild Shape Retrieval from a Single Image<br>abs: <a href="https://t.co/vLfyyobpxt">https://t.co/vLfyyobpxt</a><br><br>Experiments on in-the-wild, complex imagery from ScanNet show that approach is more robust than sota in<br>real-world scenarios without any exact CAD matches <a href="https://t.co/3zVBxATR4T">pic.twitter.com/3zVBxATR4T</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1429973665194647552?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 11. A Survey on Common Threats in npm and PyPi Registries

Berkay Kaplan, Jingyu Qian

- retweets: 90, favorites: 15 (08/25/2021 08:15:58)

- links: [abs](https://arxiv.org/abs/2108.09576) | [pdf](https://arxiv.org/pdf/2108.09576)
- [cs.CR](https://arxiv.org/list/cs.CR/recent) | [cs.SE](https://arxiv.org/list/cs.SE/recent)

Software engineers regularly use JavaScript and Python for both front-end and back-end automation tasks. On top of JavaScript and Python, there are several frameworks to facilitate automation tasks further. Some of these frameworks are Node Manager Package (npm) and Python Package Index (PyPi), which are open source (OS) package libraries. The public registries npm and PyPi use to host packages allow any user with a verified email to publish code. The lack of a comprehensive scanning tool when publishing to the registry creates security concerns. Users can report malicious code on the registry; however, attackers can still cause damage until they remove their tool from the platform. Furthermore, several packages depend on each other, making them more vulnerable to a bad package in the dependency tree. The heavy code reuse creates security artifacts developers have to consider, such as the package reach. This project will illustrate a high-level overview of common risks associated with OS registries and the package dependency structure. There are several attack types, such as typosquatting and combosquatting, in the OS package registries. Outdated packages pose a security risk, and we will examine the extent of technical lag present in the npm environment. In this paper, our main contribution consists of a survey of common threats in OS registries. Afterward, we will offer countermeasures to mitigate the risks presented. These remedies will heavily focus on the applications of Machine Learning (ML) to detect suspicious activities. To the best of our knowledge, the ML-focused countermeasures are the first proposed possible solutions to the security problems listed. In addition, this project is the first survey of threats in npm and PyPi, although several studies focus on a subset of threats.




# 12. Transferring Dexterous Manipulation from GPU Simulation to a Remote  Real-World TriFinger

Arthur Allshire, Mayank Mittal, Varun Lodaya, Viktor Makoviychuk, Denys Makoviichuk, Felix Widmaier, Manuel W√ºthrich, Stefan Bauer, Ankur Handa, Animesh Garg

- retweets: 56, favorites: 23 (08/25/2021 08:15:58)

- links: [abs](https://arxiv.org/abs/2108.09779) | [pdf](https://arxiv.org/pdf/2108.09779)
- [cs.RO](https://arxiv.org/list/cs.RO/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

We present a system for learning a challenging dexterous manipulation task involving moving a cube to an arbitrary 6-DoF pose with only 3-fingers trained with NVIDIA's IsaacGym simulator. We show empirical benefits, both in simulation and sim-to-real transfer, of using keypoints as opposed to position+quaternion representations for the object pose in 6-DoF for policy observations and in reward calculation to train a model-free reinforcement learning agent. By utilizing domain randomization strategies along with the keypoint representation of the pose of the manipulated object, we achieve a high success rate of 83% on a remote TriFinger system maintained by the organizers of the Real Robot Challenge. With the aim of assisting further research in learning in-hand manipulation, we make the codebase of our system, along with trained checkpoints that come with billions of steps of experience available, at https://s2r2-ig.github.io

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Transferring Dexterous Manipulation from GPU Simulation to a Remote Real-World TriFinger<br>pdf: <a href="https://t.co/cL7UeL83Yr">https://t.co/cL7UeL83Yr</a><br>abs: <a href="https://t.co/1VvbGuA9on">https://t.co/1VvbGuA9on</a> <a href="https://t.co/SnuCjilh3s">pic.twitter.com/SnuCjilh3s</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1430001638455062535?ref_src=twsrc%5Etfw">August 24, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



