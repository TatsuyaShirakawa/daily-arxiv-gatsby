---
title: Hot Papers 2020-07-07
date: 2020-07-08T09:39:23.Z
template: "post"
draft: false
slug: "hot-papers-2020-07-07"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2020-07-07"
socialImage: "/media/42-line-bible.jpg"

---

# 1. Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group  Shift

Marvin Zhang, Henrik Marklund, Abhishek Gupta, Sergey Levine, Chelsea Finn

- retweets: 107, favorites: 581 (07/08/2020 09:39:23)

- links: [abs](https://arxiv.org/abs/2007.02931) | [pdf](https://arxiv.org/pdf/2007.02931)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

A fundamental assumption of most machine learning algorithms is that the training and test data are drawn from the same underlying distribution. However, this assumption is violated in almost all practical applications: machine learning systems are regularly tested on data that are structurally different from the training set, either due to temporal correlations, particular end users, or other factors. In this work, we consider the setting where test examples are not drawn from the training distribution. Prior work has approached this problem by attempting to be robust to all possible test time distributions, which may degrade average performance, or by "peeking" at the test examples during training, which is not always feasible. In contrast, we propose to learn models that are adaptable, such that they can adapt to distribution shift at test time using a batch of unlabeled test data points. We acquire such models by learning to adapt to training batches sampled according to different sub-distributions, which simulate structural distribution shifts that may occur at test time. We introduce the problem of adaptive risk minimization (ARM), a formalization of this setting that lends itself to meta-learning methods. Compared to a variety of methods under the paradigms of empirical risk minimization and robust optimization, our approach provides substantial empirical gains on image classification problems in the presence of distribution shift.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Supervised ML methods (i.e. ERM) assume that train &amp; test data are from the same distribution, &amp; deteriorate when this assumption is broken.<br><br>To help, we introduce adaptive risk minimization (ARM):<a href="https://t.co/y3l2KCmmiB">https://t.co/y3l2KCmmiB</a><br><br>With M Zhang, H Marklund <a href="https://twitter.com/abhishekunique7?ref_src=twsrc%5Etfw">@abhishekunique7</a> <a href="https://twitter.com/svlevine?ref_src=twsrc%5Etfw">@svlevine</a><br>(1/6)</p>&mdash; Chelsea Finn (@chelseabfinn) <a href="https://twitter.com/chelseabfinn/status/1280329404925673474?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows

Didrik Nielsen, Priyank Jaini, Emiel Hoogeboom, Ole Winther, Max Welling

- retweets: 67, favorites: 303 (07/08/2020 09:39:23)

- links: [abs](https://arxiv.org/abs/2007.02731) | [pdf](https://arxiv.org/pdf/2007.02731)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

Normalizing flows and variational autoencoders are powerful generative models that can represent complicated density functions. However, they both impose constraints on the models: Normalizing flows use bijective transformations to model densities whereas VAEs learn stochastic transformations that are non-invertible and thus typically do not provide tractable estimates of the marginal likelihood. In this paper, we introduce SurVAE Flows: A modular framework of composable transformations that encompasses VAEs and normalizing flows. SurVAE Flows bridge the gap between normalizing flows and VAEs with surjective transformations, wherein the transformations are deterministic in one direction -- thereby allowing exact likelihood computation, and stochastic in the reverse direction -- hence providing a lower bound on the corresponding likelihood. We show that several recently proposed methods, including dequantization and augmented normalizing flows, can be expressed as SurVAE Flows. Finally, we introduce common operations such as the max value, the absolute value, sorting and stochastic permutation as composable layers in SurVAE Flows.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Merging VAEs with Flows into SurVAE flows. Great work by Didrik Nielsen who was on a highly successful ELLIS exchange from Denmark TU at U. Amsterdam. (w/ E. Hoogeboom, P. Jaini, O. Winther).<a href="https://t.co/WBwOuzj3o3">https://t.co/WBwOuzj3o3</a></p>&mdash; Max Welling (@wellingmax) <a href="https://twitter.com/wellingmax/status/1280443326928490497?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">1/9 Excited to present SurVAE Flows with the brilliant <a href="https://twitter.com/nielsen_didrik?ref_src=twsrc%5Etfw">@nielsen_didrik</a> , <a href="https://twitter.com/emiel_hoogeboom?ref_src=twsrc%5Etfw">@emiel_hoogeboom</a>, Ole Winther and <a href="https://twitter.com/wellingmax?ref_src=twsrc%5Etfw">@wellingmax</a> that bridge the gap between Flows and VAEs using Surjections.<br>Paper: <a href="https://t.co/HH4FYcCpE7">https://t.co/HH4FYcCpE7</a><br>Code: <a href="https://t.co/RZJ9sxsLEs">https://t.co/RZJ9sxsLEs</a><br>Thread below. <a href="https://t.co/I5pgASaxJb">pic.twitter.com/I5pgASaxJb</a></p>&mdash; Priyank Jaini (@priyankjaini) <a href="https://twitter.com/priyankjaini/status/1280465051493609473?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">SurVAE Flowsは生成モデルの変換として全単射（正規化フロー）、確率的（VAE）以外に全射（離散化、最大値, ソート操作など）をサポートし、これらは逆変換、尤度貢献度の三つのI/Fさえ実装すれば自由に組み合わせることができ、近年提案された多くのモデルを特殊例として含む<a href="https://t.co/o5frcWBHun">https://t.co/o5frcWBHun</a></p>&mdash; Daisuke Okanohara (@hillbig) <a href="https://twitter.com/hillbig/status/1280642079073263616?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. BézierSketch: A generative model for scalable vector sketches

Ayan Das, Yongxin Yang, Timothy Hospedales, Tao Xiang, Yi-Zhe Song

- retweets: 38, favorites: 184 (07/08/2020 09:39:23)

- links: [abs](https://arxiv.org/abs/2007.02190) | [pdf](https://arxiv.org/pdf/2007.02190)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [eess.IV](https://arxiv.org/list/eess.IV/recent)

The study of neural generative models of human sketches is a fascinating contemporary modeling problem due to the links between sketch image generation and the human drawing process. The landmark SketchRNN provided breakthrough by sequentially generating sketches as a sequence of waypoints. However this leads to low-resolution image generation, and failure to model long sketches. In this paper we present B\'ezierSketch, a novel generative model for fully vector sketches that are automatically scalable and high-resolution. To this end, we first introduce a novel inverse graphics approach to stroke embedding that trains an encoder to embed each stroke to its best fit B\'ezier curve. This enables us to treat sketches as short sequences of paramaterized strokes and thus train a recurrent sketch generator with greater capacity for longer sketches, while producing scalable high-resolution results. We report qualitative and quantitative results on the Quick, Draw! benchmark.

<blockquote class="twitter-tweet"><p lang="ro" dir="ltr">BézierSketch: A generative model for scalable vector sketches<br>pdf: <a href="https://t.co/rmEPsRv4ZH">https://t.co/rmEPsRv4ZH</a><br>abs: <a href="https://t.co/v2mOg2BZtp">https://t.co/v2mOg2BZtp</a> <a href="https://t.co/wRM2IcnGfD">pic.twitter.com/wRM2IcnGfD</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1280322926189916161?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Nice results using control points for Bézier curves instead of pen stroke locations in a generative model applied on QuickDraw doodles.<br><br>Will be interesting to incorporate Bézier curve models as a prior for sketch-based models for pixel images. <a href="https://t.co/TuZvnqHAej">https://t.co/TuZvnqHAej</a> <a href="https://twitter.com/hashtag/ECCV2020?src=hash&amp;ref_src=twsrc%5Etfw">#ECCV2020</a> <a href="https://t.co/CzTz2TRB5a">https://t.co/CzTz2TRB5a</a> <a href="https://t.co/opX3Ptz5by">pic.twitter.com/opX3Ptz5by</a></p>&mdash; hardmaru (@hardmaru) <a href="https://twitter.com/hardmaru/status/1280328217476263936?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. Meta-Learning through Hebbian Plasticity in Random Networks

Elias Najarro, Sebastian Risi

- retweets: 27, favorites: 109 (07/08/2020 09:39:24)

- links: [abs](https://arxiv.org/abs/2007.02686) | [pdf](https://arxiv.org/pdf/2007.02686)
- [cs.NE](https://arxiv.org/list/cs.NE/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

Lifelong learning and adaptability are two defining aspects of biological agents. Modern reinforcement learning (RL) approaches have shown significant progress in solving complex tasks, however once training is concluded, the found solutions are typically static and incapable of adapting to new information or perturbations. While it is still not completely understood how biological brains learn and adapt so efficiently from experience, it is believed that synaptic plasticity plays a prominent role in this process. Inspired by this biological mechanism, we propose a search method that, instead of optimizing the weight parameters of neural networks directly, only searches for synapse-specific Hebbian learning rules that allow the network to continuously self-organize its weights during the lifetime of the agent. We demonstrate our approach on several reinforcement learning tasks with different sensory modalities and more than 450K trainable plasticity parameters. We find that starting from completely random weights, the discovered Hebbian rules enable an agent to navigate a dynamical 2D-pixel environment; likewise they allow a simulated 3D quadrupedal robot to learn how to walk while adapting to different morphological damage in the absence of any explicit reward or error signal.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://twitter.com/enasmel?ref_src=twsrc%5Etfw">@enasmel</a> and myself are excited to announce our paper &quot;Meta-Learning through Hebbian Plasticity in Random Networks&quot; <a href="https://t.co/UxUnRgOJRB">https://t.co/UxUnRgOJRB</a> <br><br>Instead of optimizing the neural network&#39;s weights directly, we only search for synapse-specific Hebbian learning rules. Thread 👇 <a href="https://t.co/zDiZEUuKLL">pic.twitter.com/zDiZEUuKLL</a></p>&mdash; Sebastian Risi (@risi1979) <a href="https://twitter.com/risi1979/status/1280544779630186499?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. Descent-to-Delete: Gradient-Based Methods for Machine Unlearning

Seth Neel, Aaron Roth, Saeed Sharifi-Malvajerdi

- retweets: 17, favorites: 85 (07/08/2020 09:39:24)

- links: [abs](https://arxiv.org/abs/2007.02923) | [pdf](https://arxiv.org/pdf/2007.02923)
- [stat.ML](https://arxiv.org/list/stat.ML/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent)

We study the data deletion problem for convex models. By leveraging techniques from convex optimization and reservoir sampling, we give the first data deletion algorithms that are able to handle an arbitrarily long sequence of adversarial updates while promising both per-deletion run-time and steady-state error that do not grow with the length of the update sequence. We also introduce several new conceptual distinctions: for example, we can ask that after a deletion, the entire state maintained by the optimization algorithm is statistically indistinguishable from the state that would have resulted had we retrained, or we can ask for the weaker condition that only the observable output is statistically indistinguishable from the observable output that would have resulted from retraining. We are able to give more efficient deletion algorithms under this weaker deletion criterion.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">New Preprint out today with <a href="https://twitter.com/Aaroth?ref_src=twsrc%5Etfw">@aaroth</a>, and Saeed Sharifi-Malvajerdi! “Descent-to-Delete: Gradient-Based Methods for Machine Unlearning” (<a href="https://t.co/QfdD14fpIk">https://t.co/QfdD14fpIk</a>) Motivated by GDPR&#39;s &quot;Right to be Forgotten&quot; we study the problem of efficiently deleting user data from AI models (1/n)</p>&mdash; Seth Neel (@SethVNeel) <a href="https://twitter.com/SethVNeel/status/1280543336076582912?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. A Unifying View of Optimism in Episodic Reinforcement Learning

Gergely Neu, Ciara Pike-Burke

- retweets: 12, favorites: 71 (07/08/2020 09:39:24)

- links: [abs](https://arxiv.org/abs/2007.01891) | [pdf](https://arxiv.org/pdf/2007.01891)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

The principle of optimism in the face of uncertainty underpins many theoretically successful reinforcement learning algorithms. In this paper we provide a general framework for designing, analyzing and implementing such algorithms in the episodic reinforcement learning problem. This framework is built upon Lagrangian duality, and demonstrates that every model-optimistic algorithm that constructs an optimistic MDP has an equivalent representation as a value-optimistic dynamic programming algorithm. Typically, it was thought that these two classes of algorithms were distinct, with model-optimistic algorithms benefiting from a cleaner probabilistic analysis while value-optimistic algorithms are easier to implement and thus more practical. With the framework developed in this paper, we show that it is possible to get the best of both worlds by providing a class of algorithms which have a computationally efficient dynamic-programming implementation and also a simple probabilistic analysis. Besides being able to capture many existing algorithms in the tabular setting, our framework can also address largescale problems under realizable function approximation, where it enables a simple model-based analysis of some recently proposed methods.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">New EPIC paper with <a href="https://twitter.com/CiaraPikeBurke?ref_src=twsrc%5Etfw">@CiaraPikeBurke</a> finally online!<br><br>We provide a unifying framework for optimistic RL algorithms that formally shows how optimism in the model space is *equivalent* to optimism in the value space. Also works for linear FA.<a href="https://t.co/EPvyCZUbxY">https://t.co/EPvyCZUbxY</a><br><br>THREAD👇<br><br>1/10 <a href="https://t.co/HLkRSAdF5u">pic.twitter.com/HLkRSAdF5u</a></p>&mdash; Gergely Neu (@neu_rips) <a href="https://twitter.com/neu_rips/status/1280432294113804288?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. Scaling Imitation Learning in Minecraft

Artemij Amiranashvili, Nicolai Dorka, Wolfram Burgard, Vladlen Koltun, Thomas Brox

- retweets: 11, favorites: 55 (07/08/2020 09:39:24)

- links: [abs](https://arxiv.org/abs/2007.02701) | [pdf](https://arxiv.org/pdf/2007.02701)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)

Imitation learning is a powerful family of techniques for learning sensorimotor coordination in immersive environments. We apply imitation learning to attain state-of-the-art performance on hard exploration problems in the Minecraft environment. We report experiments that highlight the influence of network architecture, loss function, and data augmentation. An early version of our approach reached second place in the MineRL competition at NeurIPS 2019. Here we report stronger results that can be used as a starting point for future competition entries and related research. Our code is available at https://github.com/amiranas/minerl_imitation_learning.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Scaling Imitation Learning in Minecraft<br>pdf: <a href="https://t.co/T8BZ6GKYCh">https://t.co/T8BZ6GKYCh</a><br>abs: <a href="https://t.co/H11XBX8JTW">https://t.co/H11XBX8JTW</a> <a href="https://t.co/9hWxYQpUnA">pic.twitter.com/9hWxYQpUnA</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1280307805421961218?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 8. HoughNet: Integrating near and long-range evidence for bottom-up object  detection

Nermin Samet, Samet Hicsonmez, Emre Akbas

- retweets: 6, favorites: 49 (07/08/2020 09:39:24)

- links: [abs](https://arxiv.org/abs/2007.02355) | [pdf](https://arxiv.org/pdf/2007.02355)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)

This paper presents HoughNet, a one-stage, anchor-free, voting-based, bottom-up object detection method. Inspired by the Generalized Hough Transform, HoughNet determines the presence of an object at a certain location by the sum of the votes cast on that location. Votes are collected from both near and long-distance locations based on a log-polar vote field. Thanks to this voting mechanism, HoughNet is able to integrate both near and long-range, class-conditional evidence for visual recognition, thereby generalizing and enhancing current object detection methodology, which typically relies on only local evidence. On the COCO dataset, HoughNet achieves 46.4 AP (and 65.1 AP_50), performing on par with the state-of-the-art in bottom-up object detection and outperforming most major one-stage and two-stage methods. We further validate the effectiveness of our proposal in another task, namely, "labels to photo" image generation by integrating the voting module of HoughNet to two different GAN models and showing that the accuracy is significantly improved in both cases. Code is available at: https://github.com/nerminsamet/houghnet

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">New paper! &quot;HoughNet: Integrating near and long-range evidence for bottom-up object detection&quot; by Nermin Samet, Samet Hicsonmez and Emre Akbas, accepted to <a href="https://twitter.com/hashtag/ECCV2020?src=hash&amp;ref_src=twsrc%5Etfw">#ECCV2020</a>. Paper: <a href="https://t.co/K4KfmbIVH9">https://t.co/K4KfmbIVH9</a>  Code: <a href="https://t.co/3MIXqy4YbV">https://t.co/3MIXqy4YbV</a> <a href="https://twitter.com/nemka_?ref_src=twsrc%5Etfw">@nemka_</a> <a href="https://twitter.com/giddyyupp?ref_src=twsrc%5Etfw">@giddyyupp</a> <a href="https://twitter.com/eakbas2?ref_src=twsrc%5Etfw">@eakbas2</a> <a href="https://t.co/1d3mY3BN4A">pic.twitter.com/1d3mY3BN4A</a></p>&mdash; METU ImageLab (@metu_imagelab) <a href="https://twitter.com/metu_imagelab/status/1280448975766786060?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. Finding Symmetry Breaking Order Parameters with Euclidean Neural  Networks

Tess E. Smidt, Mario Geiger, Benjamin Kurt Miller

- retweets: 10, favorites: 43 (07/08/2020 09:39:25)

- links: [abs](https://arxiv.org/abs/2007.02005) | [pdf](https://arxiv.org/pdf/2007.02005)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cond-mat.dis-nn](https://arxiv.org/list/cond-mat.dis-nn/recent) | [physics.comp-ph](https://arxiv.org/list/physics.comp-ph/recent)

Curie's principle states that "when effects show certain asymmetry, this asymmetry must be found in the causes that gave rise to them". We demonstrate that symmetry equivariant neural networks uphold Curie's principle and this property can be used to uncover symmetry breaking order parameters necessary to make input and output data symmetrically compatible. We prove these properties mathematically and demonstrate them numerically by training a Euclidean symmetry equivariant neural network to learn symmetry breaking input to deform a square into a rectangle.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">New <a href="https://twitter.com/arxiv?ref_src=twsrc%5Etfw">@arxiv</a> pre-print &quot;Finding Symmetry Breaking Order Parameters with Euclidean Neural Networks&quot; <a href="https://t.co/8dvE5xZyCf">https://t.co/8dvE5xZyCf</a><br>If you like symmetry and want to see how much you can say about a neural network trained on one example, this is the pre-print for you! <a href="https://t.co/2PcuCpMiXL">pic.twitter.com/2PcuCpMiXL</a></p>&mdash; Dr. Tess Smidt (@tesssmidt) <a href="https://twitter.com/tesssmidt/status/1280296061257478144?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



