---
title: Hot Papers 2021-04-20
date: 2021-04-21T12:37:32.Z
template: "post"
draft: false
slug: "hot-papers-2021-04-20"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2021-04-20"
socialImage: "/media/flying-marine.jpg"

---

# 1. A Practical Method for Constructing Equivariant Multilayer Perceptrons  for Arbitrary Matrix Groups

Marc Finzi, Max Welling, Andrew Gordon Wilson

- retweets: 9782, favorites: 25 (04/21/2021 12:37:34)

- links: [abs](https://arxiv.org/abs/2104.09459) | [pdf](https://arxiv.org/pdf/2104.09459)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [math.DS](https://arxiv.org/list/math.DS/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Symmetry and equivariance are key ingredients to generalization, and are underlying the massively successful CNN, GCNNs, deep sets and <br> graph networks.<br><br>I&#39;m very excited to present our new work EMLP (<a href="https://t.co/S3yTgI8u4x">https://t.co/S3yTgI8u4x</a>) with <a href="https://twitter.com/wellingmax?ref_src=twsrc%5Etfw">@wellingmax</a> and <a href="https://twitter.com/andrewgwils?ref_src=twsrc%5Etfw">@andrewgwils</a><br><br>1/8 <a href="https://t.co/DUelwdUDyZ">pic.twitter.com/DUelwdUDyZ</a></p>&mdash; Marc Finzi (@m_finzi) <a href="https://twitter.com/m_finzi/status/1384333811631235073?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. Cetacean Translation Initiative: a roadmap to deciphering the  communication of sperm whales

Jacob Andreas, Ga≈°per Begu≈°, Michael M. Bronstein, Roee Diamant, Denley Delaney, Shane Gero, Shafi Goldwasser, David F. Gruber, Sarah de Haas, Peter Malkin, Roger Payne, Giovanni Petri, Daniela Rus, Pratyusha Sharma, Dan Tchernov, Pernille T√∏nnesen, Antonio Torralba, Daniel Vogt, Robert J. Wood

- retweets: 5694, favorites: 117 (04/21/2021 12:37:36)

- links: [abs](https://arxiv.org/abs/2104.08614) | [pdf](https://arxiv.org/pdf/2104.08614)
- [cs.SD](https://arxiv.org/list/cs.SD/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.RO](https://arxiv.org/list/cs.RO/recent) | [eess.AS](https://arxiv.org/list/eess.AS/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Using AI to decipher the clicks of sperm whales: <a href="https://t.co/1ePbmtvtOI">https://t.co/1ePbmtvtOI</a><br><br>Paper: <a href="https://t.co/TA5cgmnBHi">https://t.co/TA5cgmnBHi</a><a href="https://twitter.com/ProjectCETI?ref_src=twsrc%5Etfw">@projectceti</a> w/<a href="https://twitter.com/Harvard?ref_src=twsrc%5Etfw">@Harvard</a> <a href="https://twitter.com/MIT?ref_src=twsrc%5Etfw">@MIT</a> <a href="https://twitter.com/CUNY?ref_src=twsrc%5Etfw">@CUNY</a> (v/<a href="https://twitter.com/NatGeo?ref_src=twsrc%5Etfw">@NatGeo</a>) <a href="https://t.co/GRW1ME18Wa">pic.twitter.com/GRW1ME18Wa</a></p>&mdash; MIT CSAIL (@MIT_CSAIL) <a href="https://twitter.com/MIT_CSAIL/status/1384536083216535561?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Roboticists, biologists, linguists, and AI experts attempt to decode sperm whale communication. Very excited to be part of this team working on machine learning and linguistics.<br><br>A roadmap:<a href="https://t.co/gH1YhG3UHD">https://t.co/gH1YhG3UHD</a><br><br>How does one approach a communication system of a species so <a href="https://t.co/WsuQSxdpfp">pic.twitter.com/WsuQSxdpfp</a></p>&mdash; Gasper Begus (@begusgasper) <a href="https://twitter.com/begusgasper/status/1384413362453315588?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. Multi-Modal Fusion Transformer for End-to-End Autonomous Driving

Aditya Prakash, Kashyap Chitta, Andreas Geiger

- retweets: 1641, favorites: 168 (04/21/2021 12:37:37)

- links: [abs](https://arxiv.org/abs/2104.09224) | [pdf](https://arxiv.org/pdf/2104.09224)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.RO](https://arxiv.org/list/cs.RO/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Multi-Modal Fusion Transformer for End-to-End Autonomous Driving<br>pdf: <a href="https://t.co/PtLIM5WNtD">https://t.co/PtLIM5WNtD</a><br>abs: <a href="https://t.co/rXLKnXJxfX">https://t.co/rXLKnXJxfX</a><br>github: <a href="https://t.co/c3Kci7meiE">https://t.co/c3Kci7meiE</a> <a href="https://t.co/3PGuYOuKZH">pic.twitter.com/3PGuYOuKZH</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384324274580770823?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. The Power of Scale for Parameter-Efficient Prompt Tuning

Brian Lester, Rami Al-Rfou, Noah Constant

- retweets: 1266, favorites: 278 (04/21/2021 12:37:38)

- links: [abs](https://arxiv.org/abs/2104.08691) | [pdf](https://arxiv.org/pdf/2104.08691)
- [cs.CL](https://arxiv.org/list/cs.CL/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Fine-tuning is dead. Prompts have closed the gap.<br><br>&quot;The Power of Scale for Parameter-Efficient Prompt Tuning&quot;<a href="https://t.co/g5kxMjXs9j">https://t.co/g5kxMjXs9j</a> <a href="https://t.co/pC5OiMuKIG">pic.twitter.com/pC5OiMuKIG</a></p>&mdash; Ethan Caballero (@ethancaballero) <a href="https://twitter.com/ethancaballero/status/1384548232076959745?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The Power of Scale for Parameter-Efficient Prompt Tuning<br>pdf: <a href="https://t.co/CLFjJjxyoV">https://t.co/CLFjJjxyoV</a><br>abs: <a href="https://t.co/ppMz6DpRgT">https://t.co/ppMz6DpRgT</a><br><br>&quot;Our end-to-end learned approach outperforms<br>GPT-3‚Äôs ‚Äúfew-shot‚Äù learning by a large margin&quot; <a href="https://t.co/DDVuRcc2p9">pic.twitter.com/DDVuRcc2p9</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384313129715179523?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. Metadata Normalization

Mandy Lu, Qingyu Zhao, Jiequan Zhang, Kilian M. Pohl, Li Fei-Fei, Juan Carlos Niebles, Ehsan Adeli

- retweets: 400, favorites: 97 (04/21/2021 12:37:39)

- links: [abs](https://arxiv.org/abs/2104.09052) | [pdf](https://arxiv.org/pdf/2104.09052)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Check our paper <a href="https://twitter.com/CVPR?ref_src=twsrc%5Etfw">@CVPR</a> 2021: Metadata Normalization (MDN), a new batch-level operation (end2end training) to correct the influence of metadata (<a href="https://twitter.com/hashtag/bias?src=hash&amp;ref_src=twsrc%5Etfw">#bias</a>, <a href="https://twitter.com/hashtag/confounder?src=hash&amp;ref_src=twsrc%5Etfw">#confounder</a>, you name it) on feature distributions. W/ <a href="https://twitter.com/drfeifei?ref_src=twsrc%5Etfw">@drfeifei</a> <a href="https://twitter.com/jcniebles?ref_src=twsrc%5Etfw">@jcniebles</a> et al.<a href="https://t.co/YT44EhGOl7">https://t.co/YT44EhGOl7</a><a href="https://t.co/Pee8UHuKxV">https://t.co/Pee8UHuKxV</a> <a href="https://t.co/hkNbXspA3m">pic.twitter.com/hkNbXspA3m</a></p>&mdash; Ehsan Adeli (@eadeli) <a href="https://twitter.com/eadeli/status/1384396211248013312?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. PARE: Part Attention Regressor for 3D Human Body Estimation

Muhammed Kocabas, Chun-Hao P. Huang, Otmar Hilliges, Michael J. Black

- retweets: 272, favorites: 100 (04/21/2021 12:37:39)

- links: [abs](https://arxiv.org/abs/2104.08527) | [pdf](https://arxiv.org/pdf/2104.08527)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">PARE: Part Attention Regressor for 3D Human Body Estimation<br>pdf: <a href="https://t.co/VMgM8LOOng">https://t.co/VMgM8LOOng</a><br>abs: <a href="https://t.co/7HlKBrsZZV">https://t.co/7HlKBrsZZV</a><br>project page: <a href="https://t.co/lyvHVHyhvY">https://t.co/lyvHVHyhvY</a> <a href="https://t.co/XsNif04iBQ">pic.twitter.com/XsNif04iBQ</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384358643370532870?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. Agent-Centric Representations for Multi-Agent Reinforcement Learning

Wenling Shang, Lasse Espeholt, Anton Raichuk, Tim Salimans

- retweets: 306, favorites: 51 (04/21/2021 12:37:40)

- links: [abs](https://arxiv.org/abs/2104.09402) | [pdf](https://arxiv.org/pdf/2104.09402)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Agent-Centric Representations for Multi-Agent Reinforcement Learning<br>pdf: <a href="https://t.co/e6ZtkmFxNR">https://t.co/e6ZtkmFxNR</a><br>abs: <a href="https://t.co/gOMyd8kgRB">https://t.co/gOMyd8kgRB</a><br>project page: <a href="https://t.co/LDgBW5cfX0">https://t.co/LDgBW5cfX0</a> <a href="https://t.co/yuZe8Vlt7P">pic.twitter.com/yuZe8Vlt7P</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384375231628906498?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 8. The Simpson's Paradox in the Offline Evaluation of Recommendation  Systems

Amir H. Jadidinejad, Craig Macdonald, Iadh Ounis

- retweets: 258, favorites: 61 (04/21/2021 12:37:40)

- links: [abs](https://arxiv.org/abs/2104.08912) | [pdf](https://arxiv.org/pdf/2104.08912)
- [cs.IR](https://arxiv.org/list/cs.IR/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The preprint of our ACM TOIS journal paper entitled &quot;The Simpson&#39;s Paradox in the Offline Evaluation of Recommendation Systems&quot; is now available at: <a href="https://t.co/EXQGIgtd41">https://t.co/EXQGIgtd41</a> - joint work with <a href="https://twitter.com/jadidinejad?ref_src=twsrc%5Etfw">@jadidinejad</a> and <a href="https://twitter.com/craig_macdonald?ref_src=twsrc%5Etfw">@craig_macdonald</a>  <a href="https://twitter.com/hashtag/recsys?src=hash&amp;ref_src=twsrc%5Etfw">#recsys</a></p>&mdash; Iadh Ounis (@iadh) <a href="https://twitter.com/iadh/status/1384454886859821058?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information  Retrieval Models

Nandan Thakur, Nils Reimers, Andreas R√ºckl√©, Abhishek Srivastava, Iryna Gurevych

- retweets: 156, favorites: 67 (04/21/2021 12:37:41)

- links: [abs](https://arxiv.org/abs/2104.08663) | [pdf](https://arxiv.org/pdf/2104.08663)
- [cs.IR](https://arxiv.org/list/cs.IR/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">üö®New paper alert üö®<br>üçª BEIR: a heterogeneous benchmark for IR. 17 datasets, 9 tasks with diverse domains. 9 SOTA retrieval models evaluated in a zero-shot setup.<br><br> w/ <a href="https://twitter.com/Nils_Reimers?ref_src=twsrc%5Etfw">@Nils_Reimers</a> <a href="https://twitter.com/arueckle?ref_src=twsrc%5Etfw">@arueckle</a> <a href="https://twitter.com/abhesrivas?ref_src=twsrc%5Etfw">@abhesrivas</a>, IG at <a href="https://twitter.com/UKPLab?ref_src=twsrc%5Etfw">@UKPLab</a> <br><br>pdf: <a href="https://t.co/czg9S9owWm">https://t.co/czg9S9owWm</a><br>More details, code üëá<a href="https://twitter.com/hashtag/NLProc?src=hash&amp;ref_src=twsrc%5Etfw">#NLProc</a> <a href="https://t.co/2vIbGhN6qB">pic.twitter.com/2vIbGhN6qB</a></p>&mdash; Nandan Thakur (@Nthakur20) <a href="https://twitter.com/Nthakur20/status/1384553358141313024?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 10. StylePeople: A Generative Model of Fullbody Human Avatars

Artur Grigorev, Karim Iskakov, Anastasia Ianina, Renat Bashirov, Ilya Zakharkin, Alexander Vakhitov, Victor Lempitsky

- retweets: 99, favorites: 61 (04/21/2021 12:37:41)

- links: [abs](https://arxiv.org/abs/2104.08363) | [pdf](https://arxiv.org/pdf/2104.08363)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">StylePeople: A Generative Model of Fullbody Human Avatars<br>pdf: <a href="https://t.co/aXmFkp2KEe">https://t.co/aXmFkp2KEe</a><br>abs: <a href="https://t.co/rJhz0DSUH4">https://t.co/rJhz0DSUH4</a> <a href="https://t.co/dULT9hVELe">pic.twitter.com/dULT9hVELe</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384344552547495938?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 11. Data-Efficient Language-Supervised Zero-Shot Learning with  Self-Distillation

Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, Joseph E. Gonzalez

- retweets: 81, favorites: 62 (04/21/2021 12:37:41)

- links: [abs](https://arxiv.org/abs/2104.08945) | [pdf](https://arxiv.org/pdf/2104.08945)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Data-Efficient Language-Supervised Zero-Shot Learning with Self-Distillation<br>pdf: <a href="https://t.co/CSilCeLyAE">https://t.co/CSilCeLyAE</a><br>abs: <a href="https://t.co/TUADQLD9V1">https://t.co/TUADQLD9V1</a><br><br>model achieves strong performance with only 3M image text pairs, 133x smaller than CLIP <a href="https://t.co/8Oq6qlR8nD">pic.twitter.com/8Oq6qlR8nD</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384318363766345731?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 12. Using Machine Learning at Scale in HPC Simulations with SmartSim: An  Application to Ocean Climate Modeling

Sam Partee, Matthew Ellis, Alessandro Rigazzi, Scott Bachman, Gustavo Marques, Andrew Shao, Benjamin Robbins

- retweets: 72, favorites: 16 (04/21/2021 12:37:42)

- links: [abs](https://arxiv.org/abs/2104.09355) | [pdf](https://arxiv.org/pdf/2104.09355)
- [cs.CE](https://arxiv.org/list/cs.CE/recent) | [cs.DC](https://arxiv.org/list/cs.DC/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [physics.ao-ph](https://arxiv.org/list/physics.ao-ph/recent)






# 13. Simple Type Theory is not too Simple: Grothendieck's Schemes without  Dependent Types

Anthony Bordg, Lawrence Paulson, Wenda Li

- retweets: 17, favorites: 55 (04/21/2021 12:37:42)

- links: [abs](https://arxiv.org/abs/2104.09366) | [pdf](https://arxiv.org/pdf/2104.09366)
- [math.AG](https://arxiv.org/list/math.AG/recent) | [cs.LO](https://arxiv.org/list/cs.LO/recent) | [math.LO](https://arxiv.org/list/math.LO/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A wonderful quote from <a href="https://t.co/SUJhJeC41q">https://t.co/SUJhJeC41q</a>: &quot;In formal mathematics, adding an axiom later is easier than removing one!&quot;. So few people seem to deeply understand &amp; appreciate this. It&#39;s the reason I so rabidly stick to the &#39;tiny theories&#39; method of building libraries of math.</p>&mdash; Jacques Carette (@jjcarett2) <a href="https://twitter.com/jjcarett2/status/1384495241865142273?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 14. Temporal Query Networks for Fine-grained Video Understanding

Chuhan Zhang, Ankush Gupta, Andrew Zisserman

- retweets: 30, favorites: 41 (04/21/2021 12:37:42)

- links: [abs](https://arxiv.org/abs/2104.09496) | [pdf](https://arxiv.org/pdf/2104.09496)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Temporal Query Networks for Fine-grained Video Understanding<br>pdf: <a href="https://t.co/3zQc3d6x5J">https://t.co/3zQc3d6x5J</a><br>abs: <a href="https://t.co/UiLyRaFVFP">https://t.co/UiLyRaFVFP</a><br>project page: <a href="https://t.co/wF6Err20ju">https://t.co/wF6Err20ju</a> <a href="https://t.co/7SU7CpVlul">pic.twitter.com/7SU7CpVlul</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384365190943330304?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 15. FiG-NeRF: Figure-Ground Neural Radiance Fields for 3D Object Category  Modelling

Christopher Xie, Keunhong Park, Ricardo Martin-Brualla, Matthew Brown

- retweets: 25, favorites: 38 (04/21/2021 12:37:42)

- links: [abs](https://arxiv.org/abs/2104.08418) | [pdf](https://arxiv.org/pdf/2104.08418)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">FiG-NeRF: Figure-Ground Neural Radiance Fields for 3D Object Category Modelling<br>pdf: <a href="https://t.co/oPLjUBskuh">https://t.co/oPLjUBskuh</a><br>abs: <a href="https://t.co/PWo8gSs4Xl">https://t.co/PWo8gSs4Xl</a> <a href="https://t.co/8bnwdGqUq0">pic.twitter.com/8bnwdGqUq0</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384336750663794689?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 16. GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation

Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, Woomyeong Park

- retweets: 20, favorites: 38 (04/21/2021 12:37:43)

- links: [abs](https://arxiv.org/abs/2104.08826) | [pdf](https://arxiv.org/pdf/2104.08826)
- [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)



<blockquote class="twitter-tweet"><p lang="fr" dir="ltr">GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation<br>pdf: <a href="https://t.co/mFm2P3EFac">https://t.co/mFm2P3EFac</a><br>abs: <a href="https://t.co/PXp3goC7ni">https://t.co/PXp3goC7ni</a> <a href="https://t.co/bM9GKfVbEt">pic.twitter.com/bM9GKfVbEt</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384314978547601409?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 17. Self-supervised Representation Learning With Path Integral Clustering  For Speaker Diarization

Prachi Singh, Sriram Ganapathy

- retweets: 12, favorites: 42 (04/21/2021 12:37:43)

- links: [abs](https://arxiv.org/abs/2104.09456) | [pdf](https://arxiv.org/pdf/2104.09456)
- [eess.AS](https://arxiv.org/list/eess.AS/recent) | [cs.SD](https://arxiv.org/list/cs.SD/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our work on self-supervised learning for speaker diarization is accepted for IEEE Tran. on Audio Speech and Lang. Proc. <br>Self-supervised learning is a branch of unsupervised learning where the data provides supervision labels.<a href="https://t.co/NiI7AndDwD">https://t.co/NiI7AndDwD</a><a href="https://twitter.com/hashtag/MachineLearning?src=hash&amp;ref_src=twsrc%5Etfw">#MachineLearning</a>  <a href="https://twitter.com/hashtag/research?src=hash&amp;ref_src=twsrc%5Etfw">#research</a> <a href="https://t.co/P3znKyQHfE">pic.twitter.com/P3znKyQHfE</a></p>&mdash; Sriram Ganapathy (@tweet4sri) <a href="https://twitter.com/tweet4sri/status/1384380181805105157?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 18. CLIPScore: A Reference-free Evaluation Metric for Image Captioning

Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, Yejin Choi

- retweets: 22, favorites: 30 (04/21/2021 12:37:43)

- links: [abs](https://arxiv.org/abs/2104.08718) | [pdf](https://arxiv.org/pdf/2104.08718)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">CLIPScore: A Reference-free Evaluation Metric for Image Captioning<br><br>CLIP can be used for robust automatic evaluation of image captioning without the need for references<br><br>pdf: <a href="https://t.co/dK9IcPHLf8">https://t.co/dK9IcPHLf8</a><br>abs: <a href="https://t.co/zlD3NrlcU1">https://t.co/zlD3NrlcU1</a> <a href="https://t.co/NdkmIDfzQC">pic.twitter.com/NdkmIDfzQC</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384311797528756226?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 19. On the Robustness to Misspecification of $Œ±$-Posteriors and Their  Variational Approximations

Marco Avella Medina, Jos√© Luis Montiel Olea, Cynthia Rush, Amilcar Velez

- retweets: 20, favorites: 31 (04/21/2021 12:37:43)

- links: [abs](https://arxiv.org/abs/2104.08324) | [pdf](https://arxiv.org/pdf/2104.08324)
- [stat.ML](https://arxiv.org/list/stat.ML/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [math.ST](https://arxiv.org/list/math.ST/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A new preprint on variational approximations of Œ±-posteriors by M. Avella Medina, J. L. Montiel Olea, C. Rush &amp; A. Velez.<br><br>They prove Bernstein von Mises theorems. The way the asymptotic variance depends on Œ± is very important. See Theorem 3 ü§©<a href="https://t.co/W9HXuNngwY">https://t.co/W9HXuNngwY</a></p>&mdash; Pierre Alquier (@PierreAlquier) <a href="https://twitter.com/PierreAlquier/status/1384345130493046787?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



