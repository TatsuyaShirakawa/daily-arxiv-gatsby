---
title: Hot Papers 2021-04-20
date: 2021-04-21T12:37:32.Z
template: "post"
draft: false
slug: "hot-papers-2021-04-20"
category: "arXiv"
tags:
  - "arXiv"
  - "Twitter"
  - "Machine Learning"
  - "Computer Science"
description: "Hot papers 2021-04-20"
socialImage: "/media/flying-marine.jpg"

---

# 1. A Practical Method for Constructing Equivariant Multilayer Perceptrons  for Arbitrary Matrix Groups

Marc Finzi, Max Welling, Andrew Gordon Wilson

- retweets: 9782, favorites: 25 (04/21/2021 12:37:34)

- links: [abs](https://arxiv.org/abs/2104.09459) | [pdf](https://arxiv.org/pdf/2104.09459)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [math.DS](https://arxiv.org/list/math.DS/recent) | [stat.ML](https://arxiv.org/list/stat.ML/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Symmetry and equivariance are key ingredients to generalization, and are underlying the massively successful CNN, GCNNs, deep sets and <br> graph networks.<br><br>I&#39;m very excited to present our new work EMLP (<a href="https://t.co/S3yTgI8u4x">https://t.co/S3yTgI8u4x</a>) with <a href="https://twitter.com/wellingmax?ref_src=twsrc%5Etfw">@wellingmax</a> and <a href="https://twitter.com/andrewgwils?ref_src=twsrc%5Etfw">@andrewgwils</a><br><br>1/8 <a href="https://t.co/DUelwdUDyZ">pic.twitter.com/DUelwdUDyZ</a></p>&mdash; Marc Finzi (@m_finzi) <a href="https://twitter.com/m_finzi/status/1384333811631235073?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 2. Cetacean Translation Initiative: a roadmap to deciphering the  communication of sperm whales

Jacob Andreas, Gašper Beguš, Michael M. Bronstein, Roee Diamant, Denley Delaney, Shane Gero, Shafi Goldwasser, David F. Gruber, Sarah de Haas, Peter Malkin, Roger Payne, Giovanni Petri, Daniela Rus, Pratyusha Sharma, Dan Tchernov, Pernille Tønnesen, Antonio Torralba, Daniel Vogt, Robert J. Wood

- retweets: 5694, favorites: 117 (04/21/2021 12:37:36)

- links: [abs](https://arxiv.org/abs/2104.08614) | [pdf](https://arxiv.org/pdf/2104.08614)
- [cs.SD](https://arxiv.org/list/cs.SD/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.RO](https://arxiv.org/list/cs.RO/recent) | [eess.AS](https://arxiv.org/list/eess.AS/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Using AI to decipher the clicks of sperm whales: <a href="https://t.co/1ePbmtvtOI">https://t.co/1ePbmtvtOI</a><br><br>Paper: <a href="https://t.co/TA5cgmnBHi">https://t.co/TA5cgmnBHi</a><a href="https://twitter.com/ProjectCETI?ref_src=twsrc%5Etfw">@projectceti</a> w/<a href="https://twitter.com/Harvard?ref_src=twsrc%5Etfw">@Harvard</a> <a href="https://twitter.com/MIT?ref_src=twsrc%5Etfw">@MIT</a> <a href="https://twitter.com/CUNY?ref_src=twsrc%5Etfw">@CUNY</a> (v/<a href="https://twitter.com/NatGeo?ref_src=twsrc%5Etfw">@NatGeo</a>) <a href="https://t.co/GRW1ME18Wa">pic.twitter.com/GRW1ME18Wa</a></p>&mdash; MIT CSAIL (@MIT_CSAIL) <a href="https://twitter.com/MIT_CSAIL/status/1384536083216535561?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Roboticists, biologists, linguists, and AI experts attempt to decode sperm whale communication. Very excited to be part of this team working on machine learning and linguistics.<br><br>A roadmap:<a href="https://t.co/gH1YhG3UHD">https://t.co/gH1YhG3UHD</a><br><br>How does one approach a communication system of a species so <a href="https://t.co/WsuQSxdpfp">pic.twitter.com/WsuQSxdpfp</a></p>&mdash; Gasper Begus (@begusgasper) <a href="https://twitter.com/begusgasper/status/1384413362453315588?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 3. Multi-Modal Fusion Transformer for End-to-End Autonomous Driving

Aditya Prakash, Kashyap Chitta, Andreas Geiger

- retweets: 1641, favorites: 168 (04/21/2021 12:37:37)

- links: [abs](https://arxiv.org/abs/2104.09224) | [pdf](https://arxiv.org/pdf/2104.09224)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.RO](https://arxiv.org/list/cs.RO/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Multi-Modal Fusion Transformer for End-to-End Autonomous Driving<br>pdf: <a href="https://t.co/PtLIM5WNtD">https://t.co/PtLIM5WNtD</a><br>abs: <a href="https://t.co/rXLKnXJxfX">https://t.co/rXLKnXJxfX</a><br>github: <a href="https://t.co/c3Kci7meiE">https://t.co/c3Kci7meiE</a> <a href="https://t.co/3PGuYOuKZH">pic.twitter.com/3PGuYOuKZH</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384324274580770823?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 4. The Power of Scale for Parameter-Efficient Prompt Tuning

Brian Lester, Rami Al-Rfou, Noah Constant

- retweets: 1266, favorites: 278 (04/21/2021 12:37:38)

- links: [abs](https://arxiv.org/abs/2104.08691) | [pdf](https://arxiv.org/pdf/2104.08691)
- [cs.CL](https://arxiv.org/list/cs.CL/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Fine-tuning is dead. Prompts have closed the gap.<br><br>&quot;The Power of Scale for Parameter-Efficient Prompt Tuning&quot;<a href="https://t.co/g5kxMjXs9j">https://t.co/g5kxMjXs9j</a> <a href="https://t.co/pC5OiMuKIG">pic.twitter.com/pC5OiMuKIG</a></p>&mdash; Ethan Caballero (@ethancaballero) <a href="https://twitter.com/ethancaballero/status/1384548232076959745?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The Power of Scale for Parameter-Efficient Prompt Tuning<br>pdf: <a href="https://t.co/CLFjJjxyoV">https://t.co/CLFjJjxyoV</a><br>abs: <a href="https://t.co/ppMz6DpRgT">https://t.co/ppMz6DpRgT</a><br><br>&quot;Our end-to-end learned approach outperforms<br>GPT-3’s “few-shot” learning by a large margin&quot; <a href="https://t.co/DDVuRcc2p9">pic.twitter.com/DDVuRcc2p9</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384313129715179523?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 5. Metadata Normalization

Mandy Lu, Qingyu Zhao, Jiequan Zhang, Kilian M. Pohl, Li Fei-Fei, Juan Carlos Niebles, Ehsan Adeli

- retweets: 400, favorites: 97 (04/21/2021 12:37:39)

- links: [abs](https://arxiv.org/abs/2104.09052) | [pdf](https://arxiv.org/pdf/2104.09052)
- [cs.LG](https://arxiv.org/list/cs.LG/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Check our paper <a href="https://twitter.com/CVPR?ref_src=twsrc%5Etfw">@CVPR</a> 2021: Metadata Normalization (MDN), a new batch-level operation (end2end training) to correct the influence of metadata (<a href="https://twitter.com/hashtag/bias?src=hash&amp;ref_src=twsrc%5Etfw">#bias</a>, <a href="https://twitter.com/hashtag/confounder?src=hash&amp;ref_src=twsrc%5Etfw">#confounder</a>, you name it) on feature distributions. W/ <a href="https://twitter.com/drfeifei?ref_src=twsrc%5Etfw">@drfeifei</a> <a href="https://twitter.com/jcniebles?ref_src=twsrc%5Etfw">@jcniebles</a> et al.<a href="https://t.co/YT44EhGOl7">https://t.co/YT44EhGOl7</a><a href="https://t.co/Pee8UHuKxV">https://t.co/Pee8UHuKxV</a> <a href="https://t.co/hkNbXspA3m">pic.twitter.com/hkNbXspA3m</a></p>&mdash; Ehsan Adeli (@eadeli) <a href="https://twitter.com/eadeli/status/1384396211248013312?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 6. PARE: Part Attention Regressor for 3D Human Body Estimation

Muhammed Kocabas, Chun-Hao P. Huang, Otmar Hilliges, Michael J. Black

- retweets: 272, favorites: 100 (04/21/2021 12:37:39)

- links: [abs](https://arxiv.org/abs/2104.08527) | [pdf](https://arxiv.org/pdf/2104.08527)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">PARE: Part Attention Regressor for 3D Human Body Estimation<br>pdf: <a href="https://t.co/VMgM8LOOng">https://t.co/VMgM8LOOng</a><br>abs: <a href="https://t.co/7HlKBrsZZV">https://t.co/7HlKBrsZZV</a><br>project page: <a href="https://t.co/lyvHVHyhvY">https://t.co/lyvHVHyhvY</a> <a href="https://t.co/XsNif04iBQ">pic.twitter.com/XsNif04iBQ</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384358643370532870?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 7. Agent-Centric Representations for Multi-Agent Reinforcement Learning

Wenling Shang, Lasse Espeholt, Anton Raichuk, Tim Salimans

- retweets: 306, favorites: 51 (04/21/2021 12:37:40)

- links: [abs](https://arxiv.org/abs/2104.09402) | [pdf](https://arxiv.org/pdf/2104.09402)
- [cs.LG](https://arxiv.org/list/cs.LG/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Agent-Centric Representations for Multi-Agent Reinforcement Learning<br>pdf: <a href="https://t.co/e6ZtkmFxNR">https://t.co/e6ZtkmFxNR</a><br>abs: <a href="https://t.co/gOMyd8kgRB">https://t.co/gOMyd8kgRB</a><br>project page: <a href="https://t.co/LDgBW5cfX0">https://t.co/LDgBW5cfX0</a> <a href="https://t.co/yuZe8Vlt7P">pic.twitter.com/yuZe8Vlt7P</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384375231628906498?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 8. The Simpson's Paradox in the Offline Evaluation of Recommendation  Systems

Amir H. Jadidinejad, Craig Macdonald, Iadh Ounis

- retweets: 258, favorites: 61 (04/21/2021 12:37:40)

- links: [abs](https://arxiv.org/abs/2104.08912) | [pdf](https://arxiv.org/pdf/2104.08912)
- [cs.IR](https://arxiv.org/list/cs.IR/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The preprint of our ACM TOIS journal paper entitled &quot;The Simpson&#39;s Paradox in the Offline Evaluation of Recommendation Systems&quot; is now available at: <a href="https://t.co/EXQGIgtd41">https://t.co/EXQGIgtd41</a> - joint work with <a href="https://twitter.com/jadidinejad?ref_src=twsrc%5Etfw">@jadidinejad</a> and <a href="https://twitter.com/craig_macdonald?ref_src=twsrc%5Etfw">@craig_macdonald</a>  <a href="https://twitter.com/hashtag/recsys?src=hash&amp;ref_src=twsrc%5Etfw">#recsys</a></p>&mdash; Iadh Ounis (@iadh) <a href="https://twitter.com/iadh/status/1384454886859821058?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 9. BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information  Retrieval Models

Nandan Thakur, Nils Reimers, Andreas Rücklé, Abhishek Srivastava, Iryna Gurevych

- retweets: 156, favorites: 67 (04/21/2021 12:37:41)

- links: [abs](https://arxiv.org/abs/2104.08663) | [pdf](https://arxiv.org/pdf/2104.08663)
- [cs.IR](https://arxiv.org/list/cs.IR/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">🚨New paper alert 🚨<br>🍻 BEIR: a heterogeneous benchmark for IR. 17 datasets, 9 tasks with diverse domains. 9 SOTA retrieval models evaluated in a zero-shot setup.<br><br> w/ <a href="https://twitter.com/Nils_Reimers?ref_src=twsrc%5Etfw">@Nils_Reimers</a> <a href="https://twitter.com/arueckle?ref_src=twsrc%5Etfw">@arueckle</a> <a href="https://twitter.com/abhesrivas?ref_src=twsrc%5Etfw">@abhesrivas</a>, IG at <a href="https://twitter.com/UKPLab?ref_src=twsrc%5Etfw">@UKPLab</a> <br><br>pdf: <a href="https://t.co/czg9S9owWm">https://t.co/czg9S9owWm</a><br>More details, code 👇<a href="https://twitter.com/hashtag/NLProc?src=hash&amp;ref_src=twsrc%5Etfw">#NLProc</a> <a href="https://t.co/2vIbGhN6qB">pic.twitter.com/2vIbGhN6qB</a></p>&mdash; Nandan Thakur (@Nthakur20) <a href="https://twitter.com/Nthakur20/status/1384553358141313024?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 10. StylePeople: A Generative Model of Fullbody Human Avatars

Artur Grigorev, Karim Iskakov, Anastasia Ianina, Renat Bashirov, Ilya Zakharkin, Alexander Vakhitov, Victor Lempitsky

- retweets: 99, favorites: 61 (04/21/2021 12:37:41)

- links: [abs](https://arxiv.org/abs/2104.08363) | [pdf](https://arxiv.org/pdf/2104.08363)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">StylePeople: A Generative Model of Fullbody Human Avatars<br>pdf: <a href="https://t.co/aXmFkp2KEe">https://t.co/aXmFkp2KEe</a><br>abs: <a href="https://t.co/rJhz0DSUH4">https://t.co/rJhz0DSUH4</a> <a href="https://t.co/dULT9hVELe">pic.twitter.com/dULT9hVELe</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384344552547495938?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 11. Data-Efficient Language-Supervised Zero-Shot Learning with  Self-Distillation

Ruizhe Cheng, Bichen Wu, Peizhao Zhang, Peter Vajda, Joseph E. Gonzalez

- retweets: 81, favorites: 62 (04/21/2021 12:37:41)

- links: [abs](https://arxiv.org/abs/2104.08945) | [pdf](https://arxiv.org/pdf/2104.08945)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Data-Efficient Language-Supervised Zero-Shot Learning with Self-Distillation<br>pdf: <a href="https://t.co/CSilCeLyAE">https://t.co/CSilCeLyAE</a><br>abs: <a href="https://t.co/TUADQLD9V1">https://t.co/TUADQLD9V1</a><br><br>model achieves strong performance with only 3M image text pairs, 133x smaller than CLIP <a href="https://t.co/8Oq6qlR8nD">pic.twitter.com/8Oq6qlR8nD</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384318363766345731?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 12. Using Machine Learning at Scale in HPC Simulations with SmartSim: An  Application to Ocean Climate Modeling

Sam Partee, Matthew Ellis, Alessandro Rigazzi, Scott Bachman, Gustavo Marques, Andrew Shao, Benjamin Robbins

- retweets: 72, favorites: 16 (04/21/2021 12:37:42)

- links: [abs](https://arxiv.org/abs/2104.09355) | [pdf](https://arxiv.org/pdf/2104.09355)
- [cs.CE](https://arxiv.org/list/cs.CE/recent) | [cs.DC](https://arxiv.org/list/cs.DC/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [physics.ao-ph](https://arxiv.org/list/physics.ao-ph/recent)






# 13. Simple Type Theory is not too Simple: Grothendieck's Schemes without  Dependent Types

Anthony Bordg, Lawrence Paulson, Wenda Li

- retweets: 17, favorites: 55 (04/21/2021 12:37:42)

- links: [abs](https://arxiv.org/abs/2104.09366) | [pdf](https://arxiv.org/pdf/2104.09366)
- [math.AG](https://arxiv.org/list/math.AG/recent) | [cs.LO](https://arxiv.org/list/cs.LO/recent) | [math.LO](https://arxiv.org/list/math.LO/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A wonderful quote from <a href="https://t.co/SUJhJeC41q">https://t.co/SUJhJeC41q</a>: &quot;In formal mathematics, adding an axiom later is easier than removing one!&quot;. So few people seem to deeply understand &amp; appreciate this. It&#39;s the reason I so rabidly stick to the &#39;tiny theories&#39; method of building libraries of math.</p>&mdash; Jacques Carette (@jjcarett2) <a href="https://twitter.com/jjcarett2/status/1384495241865142273?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 14. Temporal Query Networks for Fine-grained Video Understanding

Chuhan Zhang, Ankush Gupta, Andrew Zisserman

- retweets: 30, favorites: 41 (04/21/2021 12:37:42)

- links: [abs](https://arxiv.org/abs/2104.09496) | [pdf](https://arxiv.org/pdf/2104.09496)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Temporal Query Networks for Fine-grained Video Understanding<br>pdf: <a href="https://t.co/3zQc3d6x5J">https://t.co/3zQc3d6x5J</a><br>abs: <a href="https://t.co/UiLyRaFVFP">https://t.co/UiLyRaFVFP</a><br>project page: <a href="https://t.co/wF6Err20ju">https://t.co/wF6Err20ju</a> <a href="https://t.co/7SU7CpVlul">pic.twitter.com/7SU7CpVlul</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384365190943330304?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 15. FiG-NeRF: Figure-Ground Neural Radiance Fields for 3D Object Category  Modelling

Christopher Xie, Keunhong Park, Ricardo Martin-Brualla, Matthew Brown

- retweets: 25, favorites: 38 (04/21/2021 12:37:42)

- links: [abs](https://arxiv.org/abs/2104.08418) | [pdf](https://arxiv.org/pdf/2104.08418)
- [cs.CV](https://arxiv.org/list/cs.CV/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">FiG-NeRF: Figure-Ground Neural Radiance Fields for 3D Object Category Modelling<br>pdf: <a href="https://t.co/oPLjUBskuh">https://t.co/oPLjUBskuh</a><br>abs: <a href="https://t.co/PWo8gSs4Xl">https://t.co/PWo8gSs4Xl</a> <a href="https://t.co/8bnwdGqUq0">pic.twitter.com/8bnwdGqUq0</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384336750663794689?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 16. GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation

Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, Woomyeong Park

- retweets: 20, favorites: 38 (04/21/2021 12:37:43)

- links: [abs](https://arxiv.org/abs/2104.08826) | [pdf](https://arxiv.org/pdf/2104.08826)
- [cs.CL](https://arxiv.org/list/cs.CL/recent) | [cs.AI](https://arxiv.org/list/cs.AI/recent)



<blockquote class="twitter-tweet"><p lang="fr" dir="ltr">GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation<br>pdf: <a href="https://t.co/mFm2P3EFac">https://t.co/mFm2P3EFac</a><br>abs: <a href="https://t.co/PXp3goC7ni">https://t.co/PXp3goC7ni</a> <a href="https://t.co/bM9GKfVbEt">pic.twitter.com/bM9GKfVbEt</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384314978547601409?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 17. Self-supervised Representation Learning With Path Integral Clustering  For Speaker Diarization

Prachi Singh, Sriram Ganapathy

- retweets: 12, favorites: 42 (04/21/2021 12:37:43)

- links: [abs](https://arxiv.org/abs/2104.09456) | [pdf](https://arxiv.org/pdf/2104.09456)
- [eess.AS](https://arxiv.org/list/eess.AS/recent) | [cs.SD](https://arxiv.org/list/cs.SD/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our work on self-supervised learning for speaker diarization is accepted for IEEE Tran. on Audio Speech and Lang. Proc. <br>Self-supervised learning is a branch of unsupervised learning where the data provides supervision labels.<a href="https://t.co/NiI7AndDwD">https://t.co/NiI7AndDwD</a><a href="https://twitter.com/hashtag/MachineLearning?src=hash&amp;ref_src=twsrc%5Etfw">#MachineLearning</a>  <a href="https://twitter.com/hashtag/research?src=hash&amp;ref_src=twsrc%5Etfw">#research</a> <a href="https://t.co/P3znKyQHfE">pic.twitter.com/P3znKyQHfE</a></p>&mdash; Sriram Ganapathy (@tweet4sri) <a href="https://twitter.com/tweet4sri/status/1384380181805105157?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 18. CLIPScore: A Reference-free Evaluation Metric for Image Captioning

Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, Yejin Choi

- retweets: 22, favorites: 30 (04/21/2021 12:37:43)

- links: [abs](https://arxiv.org/abs/2104.08718) | [pdf](https://arxiv.org/pdf/2104.08718)
- [cs.CV](https://arxiv.org/list/cs.CV/recent) | [cs.CL](https://arxiv.org/list/cs.CL/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">CLIPScore: A Reference-free Evaluation Metric for Image Captioning<br><br>CLIP can be used for robust automatic evaluation of image captioning without the need for references<br><br>pdf: <a href="https://t.co/dK9IcPHLf8">https://t.co/dK9IcPHLf8</a><br>abs: <a href="https://t.co/zlD3NrlcU1">https://t.co/zlD3NrlcU1</a> <a href="https://t.co/NdkmIDfzQC">pic.twitter.com/NdkmIDfzQC</a></p>&mdash; AK (@ak92501) <a href="https://twitter.com/ak92501/status/1384311797528756226?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>




# 19. On the Robustness to Misspecification of $α$-Posteriors and Their  Variational Approximations

Marco Avella Medina, José Luis Montiel Olea, Cynthia Rush, Amilcar Velez

- retweets: 20, favorites: 31 (04/21/2021 12:37:43)

- links: [abs](https://arxiv.org/abs/2104.08324) | [pdf](https://arxiv.org/pdf/2104.08324)
- [stat.ML](https://arxiv.org/list/stat.ML/recent) | [cs.LG](https://arxiv.org/list/cs.LG/recent) | [math.ST](https://arxiv.org/list/math.ST/recent)



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A new preprint on variational approximations of α-posteriors by M. Avella Medina, J. L. Montiel Olea, C. Rush &amp; A. Velez.<br><br>They prove Bernstein von Mises theorems. The way the asymptotic variance depends on α is very important. See Theorem 3 🤩<a href="https://t.co/W9HXuNngwY">https://t.co/W9HXuNngwY</a></p>&mdash; Pierre Alquier (@PierreAlquier) <a href="https://twitter.com/PierreAlquier/status/1384345130493046787?ref_src=twsrc%5Etfw">April 20, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>



